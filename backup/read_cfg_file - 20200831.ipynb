{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from __future__ import division\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "cfgfile = \"C:/Users/HX/Desktop/yolov4.cfg\"\n",
    "model_file_path = \"Model/model.pt\"\n",
    "\n",
    "def read_cfg_file(cfgfile):\n",
    "    file = open(cfgfile, 'r')\n",
    "    lines = file.read().split('\\n')\n",
    "\n",
    "    layer_type = []\n",
    "    layer_details = []\n",
    "    current_layer_details = {}\n",
    "    for line in lines:\n",
    "        #print(line)\n",
    "        if line == '':\n",
    "            continue\n",
    "        elif line[0] == '#':\n",
    "            continue\n",
    "        else:\n",
    "            if (line[0] == '['):\n",
    "                layer_type.append(line[1 : -1])\n",
    "                if current_layer_details != {}:\n",
    "                    layer_details.append(current_layer_details)\n",
    "                    current_layer_details = {}\n",
    "            else:\n",
    "                current_layer_details.update([(line.split(\"=\")[0].rstrip(), line.split(\"=\")[1].lstrip())])\n",
    "    layer_details.append(current_layer_details)\n",
    "    return layer_type, layer_details\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * torch.tanh(F.softplus(x))\n",
    "        return x\n",
    "\n",
    "class Conv_Layer_box(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride, activation_func, batch_normalization):\n",
    "        super().__init__()\n",
    "        padding = (int((kernel_size - 1)/2), int((kernel_size - 1)/2))\n",
    "        #TBC: linear\n",
    "        dict_activation_func = {\"ReLU\": nn.ReLU(inplace=False),\n",
    "                                \"linear\": nn.ReLU(inplace=False),\n",
    "                                \"leaky\": nn.LeakyReLU(0.1, inplace=False),\n",
    "                                \"mish\": Mish()\n",
    "                               }\n",
    "        \n",
    "        if batch_normalization == True:\n",
    "            bias = False\n",
    "        else:\n",
    "            bias = True\n",
    "        self.conv_box = nn.ModuleList()\n",
    "        self.conv_box.append(nn.Conv2d(in_channel, out_channel, kernel_size, stride, padding, bias = bias))\n",
    "        if batch_normalization == True:\n",
    "            self.conv_box.append(nn.BatchNorm2d(out_channel))\n",
    "        self.conv_box.append(dict_activation_func[activation_func])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.conv_box:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "class Maxpool_pad_Layer_box(nn.Module):\n",
    "    def __init__(self, maxpool_size):\n",
    "        super().__init__()\n",
    "        self.maxpool_size = maxpool_size\n",
    "        #why there are 2 padding??????????????\n",
    "        self.pad_1 = int((self.maxpool_size - 1) / 2)\n",
    "        self.pad_2 = self.pad_1\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, (self.pad_1, self.pad_2, self.pad_1, self.pad_2), mode='replicate')\n",
    "        x = F.max_pool2d(x, self.maxpool_size, stride=1)\n",
    "        return x\n",
    "    \n",
    "class Upsample_layer(nn.Module):\n",
    "    def __init__(self, stride):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch, channel, height, width = x.data.size()\n",
    "        x = x.view(batch, channel, height, 1, width, 1).expand(batch, channel, height, self.stride, width, self.stride).clone()\n",
    "        x = x.contiguous().view(batch, channel, height * self.stride, width * self.stride).clone()\n",
    "        return x\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "class shortcut(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "class route(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_length(a_1, a_2, b_1, b_2):\n",
    "    if a_1 <=b_1 and a_2 >= b_1:\n",
    "        return (min(a_2, b_2) - b_1)\n",
    "    elif a_1 <=b_1 and a_2 <= b_1:\n",
    "        return 0\n",
    "    else:\n",
    "        return cross_length(b_1, b_2, a_1, a_2)\n",
    "\n",
    "def IoU(x_GT, y_GT, h_GT, w_GT, x_PD, y_PD, h_PD, w_PD):\n",
    "    area_of_I = cross_length(x_GT, x_GT + h_GT, x_PD, x_PD + h_PD) * cross_length(y_GT, y_GT + h_GT, y_PD, y_PD + h_PD)\n",
    "    area_of_U = h_GT * w_GT + h_PD * w_PD - area_of_I\n",
    "    return area_of_I / area_of_U\n",
    "\n",
    "\n",
    "\n",
    "def axis_conversion(x_centre, y_centre, h, w):\n",
    "    return (x_centre - h / 2, y_centre - w / 2, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.5, 4.5, 3, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25/(64)\n",
    "axis_conversion(6, 6, 3,3)\n",
    "#IoU(11,11,8,8,12,12,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yolo_input = np.array([1.0 for i in range(255 * 76 * 76 * 2)]).reshape(2, 255, 76, 76)\n",
    "Yolo_input = torch.from_numpy(Yolo_input)\n",
    "#input[:,:,0,0] = 2\n",
    "#input[:,:,0,0]\n",
    "anchors = [12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401]\n",
    "mask = [0, 1, 2]\n",
    "classes = 80\n",
    "input_image_size = 608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_on_Matrix_x = torch.from_numpy(np.array([[i for j in range(19)] for i in range(19)]))\n",
    "#add_on_Matrix_y = [[i for i in range(19)] for j in range(19)]\n",
    "#add_on_Matrix_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n#Yolo_run_layer = Yolo(anchors, mask, classes, input_image_size)\\n\\n#b_x, b_y, b_w, b_h, objective_p, class_p = Yolo_run_layer(Yolo_input)\\n#combined_yolo_output = torch.cat((b_x, b_y, b_w, b_h, objective_p, class_p), 2)\\n\\nYolo_input = np.array([1.0 for i in range(255 * 76 * 76 * 2)]).reshape(2, 255, 76, 76)\\nYolo_input = torch.from_numpy(Yolo_input)\\ntarget = np.array([0 for i in range(3 * 76 * 76 * 85)])\\ninput_tensor = Yolo_input\\noutput_tensor = torch.Tensor(target)\\n\\nlearning_rate = 0.08\\nepoch_size = 5\\nsteps_for_printing_out_loss = 1\\n\\nYOLO_Module_WIP = Yolo(anchors, mask, classes, input_image_size)\\nYOLO_Module_WIP.cuda()\\n#Model_WIP.to(device)\\nloss_functioin = nn.MSELoss()\\noptimizer = optim.SGD(YOLO_Module_WIP.parameters(), lr = learning_rate)\\n\\ninput = input_tensor.cuda()\\ntarget = output_tensor.cuda()\\n\\ndef training_model():\\n    for i in range(1, epoch_size + 1):\\n        optimizer.zero_grad()\\n        output = YOLO_Module_WIP(input.cuda())\\n        print(output.size())\\n        #b_x, b_y, b_w, b_h, objective_p, class_p = YOLO_v4_Module_WIP(input.cuda())\\n        #output = b_x\\n        loss = loss_functioin(output, target.reshape(output.size(0), output.size(1), output.size(2), output.size(3), output.size(4)))\\n        loss.backward()\\n        optimizer.step()\\n        if i % (steps_for_printing_out_loss) == 0:\\n            print('Loss (epoch: ' + str(i) + '): ' + str(loss.cpu().detach().numpy()))\\n    torch.save({'state_dict': YOLO_v4_Module_WIP.state_dict(),'optimizer': optimizer.state_dict()}, model_file_path)\\n\\ntraining_model()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Yolo(nn.Module):\n",
    "    def __init__(self, anchors, mask, classes, input_image_size):\n",
    "        super().__init__()\n",
    "        self.anchors = anchors\n",
    "        self.mask = mask\n",
    "        self.classes = classes\n",
    "        self.number_of_mask = len(mask)\n",
    "        self.input_image_size = input_image_size\n",
    "        #self.Sigmoid_layer = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        mask = self.mask\n",
    "        anchors = self.anchors\n",
    "        classes = self.classes\n",
    "        number_of_mask = self.number_of_mask\n",
    "        input_image_size = self.input_image_size\n",
    "        grid_size = int(input_image_size / x.size(2))\n",
    "        #print(grid_size)\n",
    "        #t_x = torch.from_numpy(np.array([0.0 for i in range(number_of_mask * x.size(0) * x.size(2) * x.size(3))]).reshape(number_of_mask * x.size(0), 1, x.size(2), x.size(3)))\n",
    "        t_x = [None for i in range(number_of_mask)]\n",
    "        t_y = [None for i in range(number_of_mask)]\n",
    "        t_w = [None for i in range(number_of_mask)]\n",
    "        t_h = [None for i in range(number_of_mask)]\n",
    "        objective_p = [None for i in range(number_of_mask)]\n",
    "        class_p = [None for i in range(number_of_mask)]\n",
    "        \n",
    "        #c_x = [i for i in range(x.size(2))]\n",
    "        #c_y = [i for i in range(x.size(2))]\n",
    "        \n",
    "        add_on_Matrix_x = torch.from_numpy(np.array([[i for j in range(x.size(2))] for i in range(x.size(2))])).cuda()\n",
    "        add_on_Matrix_y = torch.from_numpy(np.array([[i for i in range(x.size(2))] for j in range(x.size(2))])).cuda()\n",
    "        \n",
    "        b_x = [None for i in range(number_of_mask)]\n",
    "        b_y = [None for i in range(number_of_mask)]\n",
    "        b_w = [None for i in range(number_of_mask)]\n",
    "        b_h = [None for i in range(number_of_mask)]\n",
    "        \n",
    "        \n",
    "        anchor_shape_1 = int(len(anchors) / 2)\n",
    "        anchors = np.array(anchors).reshape(anchor_shape_1, 2)\n",
    "        \n",
    "        #print(anchors)\n",
    "        \n",
    "        p_w = [None for i in range(number_of_mask)]\n",
    "        p_h = [None for i in range(number_of_mask)]\n",
    "        \n",
    "        \n",
    "        for i in range(number_of_mask):\n",
    "            start_point = i * (5 + classes)\n",
    "            end_point = (i + 1) * (5 + classes)\n",
    "            p_w[i], p_h[i] = anchors[mask[i]]\n",
    "            #print(p_w)\n",
    "            #print(p_h)\n",
    "            \n",
    "            t_x[i] = x[:, (start_point + 0) : (start_point + 1), :, :].clone()\n",
    "            \n",
    "            t_y[i] = x[:, (start_point + 1) : (start_point + 2), :, :].clone()\n",
    "            t_w[i] = x[:, (start_point + 2) : (start_point + 3), :, :].clone()\n",
    "            t_h[i] = x[:, (start_point + 3) : (start_point + 4), :, :].clone()\n",
    "            objective_p[i] = x[:, (start_point + 4) : (start_point + 5), :, :].clone()\n",
    "            class_p[i] = x[:, (start_point + 5) : end_point, :, :].clone()\n",
    "            #print(type(t_x[i]))\n",
    "            \n",
    "            #print(F.sigmoid(t_x[i].clone()))\n",
    "            b_x[i] = F.sigmoid(t_x[i].clone()) + add_on_Matrix_x\n",
    "            #print(b_x[i])\n",
    "            b_y[i] = F.sigmoid(t_y[i].clone()) + add_on_Matrix_y\n",
    "            \n",
    "            #b_x[i][0, 0, :, :] = b_x[i][0, 0, :, :].clone()\n",
    "            #b_y[i][0, 0, :, :] = b_y[i][0, 0, :, :].clone()\n",
    "            \n",
    "            \"\"\"\n",
    "            print(t_x[i].size())\n",
    "            for m in range(x.size(2)):\n",
    "                for n in range(x.size(2)):\n",
    "                    b_x[i][:, :, c_x[m], c_y[n]] = c_x[m] + b_x[i][:, :, c_x[m], c_y[n]].clone()\n",
    "                    b_y[i][:, :, c_x[m], c_y[n]] = c_y[n] + b_y[i][:, :, c_x[m], c_y[n]].clone()\n",
    "            \"\"\"\n",
    "            #need to think whether need to use below 2 lines\n",
    "            b_x[i] = grid_size * b_x[i].clone()\n",
    "            b_y[i] = grid_size * b_y[i].clone()\n",
    "            b_w[i] = p_w[i] * torch.exp(t_w[i].clone())\n",
    "            b_h[i] = p_h[i] * torch.exp(t_h[i].clone())\n",
    "            \n",
    "            objective_p[i] = F.sigmoid(objective_p[i].clone())\n",
    "            class_p[i] = F.sigmoid(class_p[i].clone())\n",
    "            #torch.reshape(t_x[i])\n",
    "        \n",
    "        b_x = torch.stack(b_x).clone()\n",
    "        b_y = torch.stack(b_y).clone()\n",
    "        b_w = torch.stack(b_w).clone()\n",
    "        b_h = torch.stack(b_h).clone()\n",
    "        objective_p = torch.stack(objective_p).clone()\n",
    "        class_p = torch.stack(class_p).clone()\n",
    "        combined_yolo_output = torch.cat((b_x, b_y, b_w, b_h, objective_p, class_p), 2)\n",
    "        #return b_x, b_y, b_w, b_h, objective_p, class_p\n",
    "        #return combined_yolo_output\n",
    "        \n",
    "        \n",
    "        #b_x = torch.stack(b_x).clone()\n",
    "        return combined_yolo_output\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Yolo_run_layer = Yolo(anchors, mask, classes, input_image_size)\n",
    "\n",
    "#b_x, b_y, b_w, b_h, objective_p, class_p = Yolo_run_layer(Yolo_input)\n",
    "#combined_yolo_output = torch.cat((b_x, b_y, b_w, b_h, objective_p, class_p), 2)\n",
    "\n",
    "Yolo_input = np.array([1.0 for i in range(255 * 76 * 76 * 2)]).reshape(2, 255, 76, 76)\n",
    "Yolo_input = torch.from_numpy(Yolo_input)\n",
    "target = np.array([0 for i in range(3 * 76 * 76 * 85)])\n",
    "input_tensor = Yolo_input\n",
    "output_tensor = torch.Tensor(target)\n",
    "\n",
    "learning_rate = 0.08\n",
    "epoch_size = 5\n",
    "steps_for_printing_out_loss = 1\n",
    "\n",
    "YOLO_Module_WIP = Yolo(anchors, mask, classes, input_image_size)\n",
    "YOLO_Module_WIP.cuda()\n",
    "#Model_WIP.to(device)\n",
    "loss_functioin = nn.MSELoss()\n",
    "optimizer = optim.SGD(YOLO_Module_WIP.parameters(), lr = learning_rate)\n",
    "\n",
    "input = input_tensor.cuda()\n",
    "target = output_tensor.cuda()\n",
    "\n",
    "def training_model():\n",
    "    for i in range(1, epoch_size + 1):\n",
    "        optimizer.zero_grad()\n",
    "        output = YOLO_Module_WIP(input.cuda())\n",
    "        print(output.size())\n",
    "        #b_x, b_y, b_w, b_h, objective_p, class_p = YOLO_v4_Module_WIP(input.cuda())\n",
    "        #output = b_x\n",
    "        loss = loss_functioin(output, target.reshape(output.size(0), output.size(1), output.size(2), output.size(3), output.size(4)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % (steps_for_printing_out_loss) == 0:\n",
    "            print('Loss (epoch: ' + str(i) + '): ' + str(loss.cpu().detach().numpy()))\n",
    "    torch.save({'state_dict': YOLO_v4_Module_WIP.state_dict(),'optimizer': optimizer.state_dict()}, model_file_path)\n",
    "\n",
    "training_model()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_yolo_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n",
      "162\n",
      "{'batch_normalize': '1', 'filters': '64', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'mish'}\n"
     ]
    }
   ],
   "source": [
    "layer_type, layer_details = read_cfg_file(cfgfile)\n",
    "\n",
    "net_layer = layer_details[0]\n",
    "\n",
    "layer_type = layer_type[1:]\n",
    "layer_details = layer_details[1:]\n",
    "\n",
    "print(len(layer_type))\n",
    "print(len(layer_details))\n",
    "print(layer_details[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nanchor = 3\\n#yolo_layer = 3\\noutput = (19 ** 2) * (1 + 4 + 16)\\nanchor * output\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "anchor = 3\n",
    "#yolo_layer = 3\n",
    "output = (19 ** 2) * (1 + 4 + 16)\n",
    "anchor * output\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build module for entire YOLO\n",
    "class YOLO_v4_model(nn.Module):\n",
    "    def __init__(self, layer_details, layer_type):\n",
    "        super(YOLO_v4_model, self).__init__()\n",
    "        self.all_layers = nn.ModuleList()\n",
    "        all_layers = self.all_layers\n",
    "        self.layer_details = layer_details\n",
    "        self.layer_type = layer_type\n",
    "\n",
    "        for i in range(len(layer_type)):\n",
    "            if layer_type[i] == 'convolutional':\n",
    "                #print(layer_details[i])\n",
    "                #print(i)\n",
    "                try:\n",
    "                    if int(layer_details[i]['batch_normalize']) == 1:\n",
    "                        batch_normalize = True\n",
    "                    else:\n",
    "                        batch_normalize = False\n",
    "                except:\n",
    "                    batch_normalize = False\n",
    "                if i == 0:\n",
    "                    in_channel = 3\n",
    "                else:\n",
    "                    in_channel = None\n",
    "                    if layer_type[i - 1] == 'convolutional':\n",
    "                        skip_step = [0]\n",
    "                    elif layer_type[i - 1] == 'shortcut':\n",
    "                        skip_step = [int(layer_details[i - 1]['from'])]\n",
    "                    elif layer_type[i - 1] == 'route':\n",
    "                        skip_step = layer_details[i - 1]['layers'].split(\",\")\n",
    "                        \n",
    "                    \"\"\"\n",
    "                    if skip_step > 0:\n",
    "                        in_channel = int(layer_details[skip_step]['filters'])\n",
    "                    else:\n",
    "                        in_channel = int(layer_details[i - 1 + skip_step]['filters'])\n",
    "                    \"\"\"\n",
    "                    for SS in skip_step:\n",
    "                        SS = int(SS)\n",
    "                        if SS > 0:\n",
    "                            if in_channel == None:\n",
    "                                in_channel = int(layer_details[SS]['filters'])\n",
    "                            else:\n",
    "                                in_channel += int(layer_details[SS]['filters'])\n",
    "                        else:\n",
    "                            if in_channel == None:\n",
    "                                in_channel = int(layer_details[i - 1 + SS]['filters'])\n",
    "                            else:\n",
    "                                in_channel += int(layer_details[i - 1 + SS]['filters'])\n",
    "                        \n",
    "                out_channel = int(layer_details[i]['filters'])\n",
    "                kernel_size = int(layer_details[i]['size'])\n",
    "                stride = int(layer_details[i]['stride'])\n",
    "                pad = int(layer_details[i]['pad'])\n",
    "                activation_func = layer_details[i]['activation']\n",
    "                layer = Conv_Layer_box(in_channel, out_channel, kernel_size, stride, activation_func, batch_normalize)\n",
    "                #print(layer)\n",
    "            elif layer_type[i] == 'maxpool':\n",
    "                layer_details[i].update([('filters', layer_details[i - 1]['filters'])])\n",
    "                maxpool_size = int(layer_details[i]['size'])\n",
    "                #print(maxpool_size)\n",
    "                layer = Maxpool_pad_Layer_box(maxpool_size)\n",
    "                #print(layer)\n",
    "            elif layer_type[i] == 'upsample':\n",
    "                layer_details[i].update([('filters', layer_details[i - 1]['filters'])])\n",
    "                stride = int(layer_details[i]['stride'])\n",
    "                layer = Upsample_layer(stride)\n",
    "            elif layer_type[i] == 'yolo':\n",
    "                #print(\"yolo\")\n",
    "                anchors = [int(x) for x in layer_details[i]['anchors'].split(\",\")]\n",
    "                \n",
    "                mask = [int(x) for x in layer_details[i]['mask'].split(\",\")]\n",
    "                classes = int(layer_details[i]['classes'])\n",
    "                #input image size = 608 for now\n",
    "                layer = Yolo(anchors, mask, classes, input_image_size)\n",
    "                #print(anchors)\n",
    "                #print(classes)\n",
    "                #print(input_image_size)\n",
    "                #continue\n",
    "            elif layer_type[i] == 'shortcut':\n",
    "                skip_step = int(layer_details[i]['from'])\n",
    "                layer_details[i].update([('filters', layer_details[i + skip_step]['filters'])])\n",
    "                layer = shortcut()\n",
    "            elif layer_type[i] == 'route':\n",
    "                try:\n",
    "                    skip_step = int(layer_details[i]['layers'].split(\",\")[0])\n",
    "                except:\n",
    "                    skip_step = int(layer_details[i]['layers'])\n",
    "                #print(skip_step)\n",
    "                if skip_step > 0:\n",
    "                    layer_details[i].update([('filters', layer_details[skip_step]['filters'])])\n",
    "                else:\n",
    "                    layer_details[i].update([('filters', layer_details[i + skip_step]['filters'])])\n",
    "                layer = route()\n",
    "            elif layer_type[i] == 'net':\n",
    "                #print(\"net\")\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            all_layers.append(layer)\n",
    "        global all_layerrr\n",
    "        all_layerrr = all_layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        all_layers = self.all_layers\n",
    "        layers_output = [None for i in range(len(layer_type))]\n",
    "        for i in range(len(layer_type)):\n",
    "            #print(i)\n",
    "            if i == 0:\n",
    "                layers_output[i] = all_layers[i](x)\n",
    "                continue\n",
    "                \n",
    "            elif layer_type[i] == 'yolo':\n",
    "                layers_output[i] = all_layers[i](layers_output[i - 1])\n",
    "                continue\n",
    "            elif layer_type[i] == 'convolutional' or layer_type[i] == 'maxpool' or layer_type[i] == 'upsample' or layer_type[i] == 'yolo':\n",
    "                layers_output[i] = all_layers[i](layers_output[i - 1])\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    print(\"i: \" + str(i) + str(layers_output[i].size()))\n",
    "                except:\n",
    "                    print(\"go\")\n",
    "                \"\"\"\n",
    "                continue\n",
    "            elif layer_type[i] == 'shortcut':\n",
    "                skip_step = [int(layer_details[i]['from'])]\n",
    "            elif layer_type[i] == 'route':\n",
    "                skip_step = layer_details[i]['layers'].split(\",\")\n",
    "            for SS in skip_step:\n",
    "                SS = int(SS)\n",
    "                #print(\"SS\" + str(i) + str(SS))\n",
    "                #print(skip_step)\n",
    "                \n",
    "                #print(SS)\n",
    "                #print(layers_output[i])\n",
    "                #print(layers_output[i - 1 + SS])\n",
    "                \n",
    "                if SS > 0:\n",
    "                    if layers_output[i] == None:\n",
    "                        #print(layers_output[SS].size())\n",
    "                        layers_output[i] = layers_output[SS]\n",
    "                    else:\n",
    "                        #print(layers_output[SS].size())\n",
    "                        layers_output[i] = torch.cat((layers_output[i], layers_output[SS]), 1)\n",
    "                else:\n",
    "                    #print(i + SS)\n",
    "                    if layers_output[i] == None:\n",
    "                        #print(layers_output[i + SS].size())\n",
    "                        layers_output[i] = layers_output[i + SS]\n",
    "                    else:\n",
    "                        \n",
    "                        #print(layers_output[i + SS].size())\n",
    "                        layers_output[i] = torch.cat((layers_output[i], layers_output[i + SS]), 1)\n",
    "            \"\"\"\n",
    "            try:\n",
    "                print(\"i: \" + str(i) + str(layers_output[i].size()))\n",
    "            except:\n",
    "                print(\"go\")\n",
    "            \"\"\"\n",
    "        #print(layers_output[138].size())\n",
    "        return layers_output[161]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss (epoch: 1): 4857.083\n",
      "Loss (epoch: 2): 4857.065\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input = np.array([1 for i in range(608 * 608 * 3 * 1)]).reshape(1, 3, 608, 608)\n",
    "#target = np.array([0 for i in range(7 * 7 * 30)])\n",
    "target = np.array([0 for i in range(3 * 19 * 19 * 85)])\n",
    "\n",
    "input_tensor = torch.Tensor(input)\n",
    "output_tensor = torch.Tensor(target)\n",
    "\n",
    "#x = np.array([1 for i in range(608 * 608 * 3)]).reshape(1, 3, 608, 608)\n",
    "#x = torch.tensor(x)\n",
    "\n",
    "learning_rate = 0.08\n",
    "epoch_size = 2\n",
    "steps_for_printing_out_loss = 1\n",
    "\n",
    "YOLO_v4_Module_WIP = YOLO_v4_model(layer_details, layer_type)\n",
    "YOLO_v4_Module_WIP.cuda()\n",
    "\n",
    "\n",
    "\n",
    "#YOLO_v4_Module_WIP.load_state_dict(torch.load(\"D:/Installation/yolov4.pt\"))\n",
    "\n",
    "#YOLO_v4_Module_WIP.load_weights(\"â€ªD:/Installation/yolov4.weights\")\n",
    "#Model_WIP.to(device)\n",
    "loss_functioin = nn.MSELoss()\n",
    "optimizer = optim.SGD(YOLO_v4_Module_WIP.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for name, param in YOLO_v4_Module_WIP.named_parameters():\n",
    "    print('name: ', name)\n",
    "    print(type(param))\n",
    "    print('param.shape: ', param.shape)\n",
    "    print('param.requires_grad: ', param.requires_grad)\n",
    "    print('=====')\n",
    "#transfer learning:\n",
    "\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name in ['fc.weight', 'fc.bias']:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\"\"\"\n",
    "YOLO_v4_Module_WIP.load_state_dict(torch.load(\"C:/Users/HX/Desktop/model.pt\")['state_dict'])\n",
    "input = input_tensor.cuda()\n",
    "target = output_tensor.cuda()\n",
    "\n",
    "def training_model():\n",
    "    for i in range(1, epoch_size + 1):\n",
    "        optimizer.zero_grad()\n",
    "        output = YOLO_v4_Module_WIP(input.cuda())\n",
    "        #print(output.size())\n",
    "        #b_x, b_y, b_w, b_h, objective_p, class_p = YOLO_v4_Module_WIP(input.cuda())\n",
    "        #output = b_x\n",
    "        #loss = loss_functioin(output, target.reshape(output.size(0), output.size(1), output.size(2), output.size(3)))\n",
    "        \n",
    "        loss = loss_functioin(output, target.reshape(output.size(0), output.size(1), output.size(2), output.size(3), output.size(4)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % (steps_for_printing_out_loss) == 0:\n",
    "            print('Loss (epoch: ' + str(i) + '): ' + str(loss.cpu().detach().numpy()))\n",
    "    #torch.save({'state_dict': YOLO_v4_Module_WIP.state_dict(),'optimizer': optimizer.state_dict()}, model_file_path)\n",
    "\n",
    "\n",
    "training_model()\n",
    "\n",
    "#YOLO_v4_Module_WIP.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_layerrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': '1',\n",
       " 'stride': '1',\n",
       " 'pad': '1',\n",
       " 'filters': '255',\n",
       " 'activation': 'linear'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_details[160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5,\n",
       " 2.0,\n",
       " 2.375,\n",
       " 4.5,\n",
       " 5.0,\n",
       " 3.5,\n",
       " 2.25,\n",
       " 4.6875,\n",
       " 4.75,\n",
       " 3.4375,\n",
       " 4.5,\n",
       " 9.125,\n",
       " 4.4375,\n",
       " 3.4375,\n",
       " 6.0,\n",
       " 7.59375,\n",
       " 14.34375,\n",
       " 12.53125]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_layers\n",
    "n = [76, 38, 19]\n",
    "m = [608 / i for i in n for m in range(6)] \n",
    "print(m)\n",
    "\n",
    "\n",
    "anchor = [12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401]\n",
    "[anchor[i] / m[i] for i in range(len(m))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-16-13f47200f125>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-13f47200f125>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    self.YOLO_v4_layers.append(Conv_Layer_box(in_channel[i], out_channel[i], kernel_size= kernel_size[i], stride = stride[i], activation_func = activation_func[i], batch_normalization = batch_normalization[i]))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class YOLO_v4_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.YOLO_v4_layers = nn.ModuleList()\n",
    "        \n",
    "            self.YOLO_v4_layers.append(Conv_Layer_box(in_channel[i], out_channel[i], kernel_size= kernel_size[i], stride = stride[i], activation_func = activation_func[i], batch_normalization = batch_normalization[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class abc():\n",
    "    def __init__(self, qwe, out):\n",
    "        print(qwe)\n",
    "        \n",
    "abc(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = \"1,2,3\"\n",
    "m = abc.split(\",\")\n",
    "m\n",
    "abc = \"1\"\n",
    "m = abc.split(\",\")\n",
    "m\n",
    "k = 4\n",
    "\n",
    "HX = []\n",
    "\n",
    "for r in k:\n",
    "    print(r)\n",
    "    print(k[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightfile = \"D:/Installation/yolov4.weights\"\n",
    "fp = open(weightfile, 'rb')\n",
    "header = np.fromfile(fp, count=5, dtype=np.int32)\n",
    "header = torch.from_numpy(header)\n",
    "seen = header[3]\n",
    "buf = np.fromfile(fp, dtype=np.float32)\n",
    "fp.close()\n",
    "\n",
    "start = 0\n",
    "ind = -2\n",
    "buf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HX_weight = YOLO_v4_Module_WIP.state_dict()\n",
    "i = 0\n",
    "HX = []\n",
    "\n",
    "for kk in HX_weight:\n",
    "    i += 1\n",
    "    print(kk)\n",
    "    print(HX_weight[kk].size())\n",
    "    HX.append(HX_weight[kk].size())\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.load(\"D:/Installation/yolov4.pt\")\n",
    "#d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = d['model']\n",
    "weight_bank = []\n",
    "i = 0\n",
    "yolo_v4_size = []\n",
    "for kk in mm:\n",
    "    i += 1\n",
    "    print(kk)\n",
    "    print(mm[kk].size())\n",
    "    weight_bank.append(mm[kk])\n",
    "    yolo_v4_size.append(mm[kk].size())\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weight_bank)\n",
    "\n",
    "\n",
    "i = 0\n",
    "HX = []\n",
    "\n",
    "for kk in YOLO_v4_Module_WIP.state_dict():\n",
    "    print(kk)\n",
    "    YOLO_v4_Module_WIP.state_dict()[kk] = weight_bank[i]\n",
    "    i += 1\n",
    "    #HX.append(HX_weight[kk].size())\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(yolo_v4_size)):\n",
    "    #print(yolo_v4_size[i] == HX[i])\n",
    "    if (yolo_v4_size[i] == HX[i]) == False:\n",
    "        print(yolo_v4_size[i])\n",
    "        print(HX[i])\n",
    "        print(i)\n",
    "    print(yolo_v4_size[i] == HX[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOLO_v4_Module_WIP.state_dict()\n",
    "torch.save({'state_dict': YOLO_v4_Module_WIP.state_dict(),'optimizer': optimizer.state_dict()}, model_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
