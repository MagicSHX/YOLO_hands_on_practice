{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mnist import MNIST\n",
    "import torch\n",
    "from torch import nn\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * torch.tanh(F.softplus(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_Layer_box(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride, activation_func, batch_normalization):\n",
    "        super().__init__()\n",
    "        padding = (int((kernel_size - 1)/2), int((kernel_size - 1)/2))\n",
    "        \n",
    "        dict_activation_func = {\"ReLU\": nn.ReLU(inplace=True),\n",
    "                                \"Leaky\": nn.LeakyReLU(0.1, inplace=True),\n",
    "                                \"Mish\": Mish()\n",
    "                               }\n",
    "        \n",
    "        if batch_normalization == True:\n",
    "            bias = False\n",
    "        else:\n",
    "            bias = True\n",
    "        self.conv_box = nn.ModuleList()\n",
    "        self.conv_box.append(nn.Conv2d(in_channel, out_channel, kernel_size = kernel_size, stride = stride, padding = padding, bias = bias))\n",
    "        if batch_normalization == True:\n",
    "            self.conv_box.append(nn.BatchNorm2d(out_channel))\n",
    "        self.conv_box.append(dict_activation_func[activation_func])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.conv_box:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "            \n",
    "class RSL_Layer_box(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride, activation_func, batch_normalization, loop_time):\n",
    "        super().__init__()\n",
    "        self.RSL_box = nn.ModuleList()\n",
    "        \n",
    "        for k in range(loop_time):\n",
    "            for i in range(len(in_channel)):\n",
    "                self.RSL_box.append(Conv_Layer_box(in_channel[i], out_channel[i], kernel_size= kernel_size[i], stride = stride[i], activation_func = activation_func[i], batch_normalization = batch_normalization[i]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        counting = 0\n",
    "        shortcut_value = x\n",
    "        for layer in self.conv_box:\n",
    "            x = layer(x)\n",
    "            counting += 1 \n",
    "            if counting == len(in_channel):\n",
    "                x = x + shortcut_value\n",
    "                shortcut_value = x\n",
    "                counting = 0\n",
    "            \n",
    "        return x\n",
    "\n",
    "class Maxpool_pad_Layer_box(nn.Module):\n",
    "    def __init__(self, maxpool_size):\n",
    "        super().__init__()\n",
    "        self.maxpool_size = maxpool_size\n",
    "        #why there are 2 padding??????????????\n",
    "        self.pad_1 = (self.maxpool_size - 1) / 2\n",
    "        self.pad_2 = self.maxpool_size - self.pad_1\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, (self.padding1, self.padding2, self.padding1, self.padding2), mode='replicate')\n",
    "        x = F.max_pool2d(x, self.maxpool_size, stride=1)\n",
    "        return x\n",
    "class Upsample_layer(nn.Module):\n",
    "    def __init__(self, stride):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch, channel, height, width = x.data.size()\n",
    "        x = x.view(batch, channel, height, 1, width, 1).expand(batch, channel, height, self.stride, width, self.stride)\n",
    "        x = x.contiguous().view(batch, channel, height * self.stride, width * self.stride)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_v4_1st_downsampling_Layer_group(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer_0 = Conv_Layer_box(3, 32, kernel_size=3, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.conv_layer_1 = Conv_Layer_box(32, 64, kernel_size=3, stride = 2, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.conv_layer_2 = Conv_Layer_box(64, 64, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "\n",
    "        #route - name - 3\n",
    "        self.conv_layer_4 = Conv_Layer_box(64, 64, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.conv_layer_5 = Conv_Layer_box(64, 32, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.conv_layer_6 = Conv_Layer_box(32, 64, kernel_size=3, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        #shortcut?????? - name - 7\n",
    "        self.conv_layer_8 = Conv_Layer_box(64, 64, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        #route - name - 9\n",
    "        #self.conv_layer_9 = Conv_Layer_box(64, 128, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_0 = self.conv_layer_0(x)\n",
    "        out_1 = self.conv_layer_1(out_0)\n",
    "        out_4 = self.conv_layer_4(out_1)\n",
    "        out_5 = self.conv_layer_5(out_4)\n",
    "        out_6 = self.conv_layer_6(out_5)\n",
    "        shortcut_7 = out_6 + out_1\n",
    "        out_8 = self.conv_layer_8(shortcut_7)\n",
    "        out_2 = self.conv_layer_2(out_1)\n",
    "        route_9 = out_8 + out_2\n",
    "        #out_9 = self.conv_layer_9(route_9)\n",
    "        out = route_9\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_v4_2nd_downsampling_Layer_group(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer_10 = Conv_Layer_box(128, 64, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.conv_layer_11 = Conv_Layer_box(64, 128, kernel_size=3, stride = 2, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.conv_layer_12 = Conv_Layer_box(128, 64, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        #route - name - 13\n",
    "        self.conv_layer_14 = Conv_Layer_box(128, 64, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.RSL_layer = RSL_Layer_box(in_channel = [64, 64], out_channel = [64, 64], kernel_size = [1, 3], stride = [1, 1], activation_func = [\"Mish\", \"Mish\"], batch_normalization = [True, True], loop_time = 2))\n",
    "        self.conv_layer_21 = Conv_Layer_box(64, 64, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        #self.conv_layer_22 = Conv_Layer_box(64, 128, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_10 = self.conv_layer_10(x)\n",
    "        out_11 = self.conv_layer_11(out_10)\n",
    "        out_14 = self.conv_layer_14(out_11)\n",
    "        shortcut_20 = self.RSL_layer(out_14)\n",
    "        out_21 = self.conv_layer_21(shortcut_20)\n",
    "        out_12 = self.conv_layer_12(out_11)\n",
    "        route_22 = out_21 + out_12\n",
    "        #out_22 = self.conv_layer_22(route_22)\n",
    "        out = route_22\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_v4_3rd_downsampling_Layer_group(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer_23 = Conv_Layer_box(128, 128, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.conv_layer_24 = Conv_Layer_box(128, 256, kernel_size=3, stride = 2, activation_func = \"Mish\", batch_normalization = True)\n",
    "        \n",
    "        self.conv_layer_25 = Conv_Layer_box(256, 128, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        #route - name - 26\n",
    "        self.conv_layer_27 = Conv_Layer_box(256, 128, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.RSL_layer = RSL_Layer_box(in_channel = [128, 128], out_channel = [128, 128], kernel_size = [1, 3], stride = [1, 1], activation_func = [\"Mish\", \"Mish\"], batch_normalization = [True, True], loop_time = 8))\n",
    "        self.conv_layer_52 = Conv_Layer_box(128, 128, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        #self.conv_layer_53 = Conv_Layer_box(128, 256, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.conv_layer_54 = Conv_Layer_box(256, 256, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_23 = self.conv_layer_23(x)\n",
    "        out_24 = self.conv_layer_24(out_23)\n",
    "        out_27 = self.conv_layer_27(out_24)\n",
    "        shortcut_51 = self.RSL_layer(out_27)\n",
    "        out_52 = self.conv_layer_52(shortcut_51)\n",
    "        out_25 = self.conv_layer_25(out_24)\n",
    "        route_53 = out_52 + out_25\n",
    "        #out_53 = self.conv_layer_53(route_53)\n",
    "        out_54 = self.conv_layer_54(route_53)\n",
    "        out = out_54\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_v4_4th_downsampling_Layer_group(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer_55 = Conv_Layer_box(256, 512, kernel_size=3, stride = 2, activation_func = \"Mish\", batch_normalization = True)\n",
    "        \n",
    "        self.conv_layer_56 = Conv_Layer_box(512, 256, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        #route - name - 57\n",
    "        self.conv_layer_58 = Conv_Layer_box(512, 256, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.RSL_layer = RSL_Layer_box(in_channel = [256, 256], out_channel = [256, 256], kernel_size = [1, 3], stride = [1, 1], activation_func = [\"Mish\", \"Mish\"], batch_normalization = [True, True], loop_time = 8))\n",
    "        self.conv_layer_83 = Conv_Layer_box(256, 256, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        #self.conv_layer_84 = Conv_Layer_box(256, 512, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.conv_layer_85 = Conv_Layer_box(512, 512, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out_55 = self.conv_layer_55(out_54)\n",
    "        out_58 = self.conv_layer_58(out_55)\n",
    "        shortcut_82 = self.RSL_layer(out_58)\n",
    "        out_83 = self.conv_layer_83(shortcut_82)\n",
    "        out_56 = self.conv_layer_56(out_55)\n",
    "        route_84 = out_83 + out_56\n",
    "        #out_84 = self.conv_layer_84(route_84)\n",
    "        out_85 = self.conv_layer_85(route_84)\n",
    "        out = out_84\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_v4_5th_downsampling_Layer_group(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer_86 = Conv_Layer_box(512, 1024, kernel_size=3, stride = 2, activation_func = \"Mish\", batch_normalization = True)\n",
    "        \n",
    "        self.conv_layer_87 = Conv_Layer_box(1024, 512, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        #route - name - 88\n",
    "        self.conv_layer_89 = Conv_Layer_box(1024, 512, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.RSL_layer = RSL_Layer_box(in_channel = [512, 512], out_channel = [512, 512], kernel_size = [1, 3], stride = [1, 1], activation_func = [\"Mish\", \"Mish\"], batch_normalization = [True, True], loop_time = 4))\n",
    "        self.conv_layer_102 = Conv_Layer_box(512, 512, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.conv_layer_103 = Conv_Layer_box(512, 1024, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.conv_layer_104 = Conv_Layer_box(1024, 1024, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out_86 = self.conv_layer_86(x)\n",
    "        out_89 = self.conv_layer_89(out_86)\n",
    "        shortcut_101 = self.RSL_layer(out_89)\n",
    "        out_102 = self.conv_layer_102(shortcut_101)\n",
    "        out_87 = self.conv_layer_87(out_86)\n",
    "        route_103 = out_102 + out_87\n",
    "        out_103 = self.conv_layer_103(route_103)\n",
    "        out_104 = self.conv_layer_104(out_103)\n",
    "        out = out_104\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-92055e1b83cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mYOLO_v4_Neck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_105_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_120_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_130_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class YOLO_v4_Neck(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.conv_layer_105 = Conv_Layer_box(1024, 512, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_106 = Conv_Layer_box(512, 1024, kernel_size=3, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_107 = Conv_Layer_box(1024, 512, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        \n",
    "        self.Maxpool_pad_Layer_108 = Maxpool_pad_Layer_box(5)\n",
    "        self.Maxpool_pad_Layer_110 = Maxpool_pad_Layer_box(9)\n",
    "        self.Maxpool_pad_Layer_112 = Maxpool_pad_Layer_box(13)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #self.conv_layer_113 = Conv_Layer_box(512, 2048, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_114 = Conv_Layer_box(512, 512, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_115 = Conv_Layer_box(512, 1024, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_116 = Conv_Layer_box(1024, 512, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_117 = Conv_Layer_box(512, 256, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        \n",
    "        self.Upsample_layer_118 = Upsample_layer(stride = 2)\n",
    "        \n",
    "        self.conv_layer_120 = Conv_Layer_box(512, 256, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        \n",
    "        self.conv_layer_122 = Conv_Layer_box(256, 256, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_123 = Conv_Layer_box(256, 512, kernel_size=3, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_124 = Conv_Layer_box(512, 256, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        \n",
    "        self.conv_layer_125 = Conv_Layer_box(256, 512, kernel_size=3, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_126 = Conv_Layer_box(512, 256, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_127 = Conv_Layer_box(256, 128, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        \n",
    "        self.Upsample_layer_128 = Upsample_layer(stride = 2)\n",
    "        \n",
    "        self.conv_layer_130 = Conv_Layer_box(256, 128, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        \n",
    "        self.conv_layer_132 = Conv_Layer_box(128, 128, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_133 = Conv_Layer_box(128, 256, kernel_size=3, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_134 = Conv_Layer_box(256, 128, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_135 = Conv_Layer_box(128, 256, kernel_size=3, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_136 = Conv_Layer_box(256, 128, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, layer_105_in, layer_120_in, layer_130_in):\n",
    "        out_105 = self.conv_layer_105(layer_105_in)\n",
    "        out_106 = self.conv_layer_106(out_105)\n",
    "        out_107 = self.conv_layer_107(out_106)\n",
    "        \n",
    "        out_108 = Maxpool_pad_Layer_108(out_107)\n",
    "        out_110 = Maxpool_pad_Layer_108(out_107)\n",
    "        out_112 = Maxpool_pad_Layer_108(out_107)\n",
    "        \n",
    "        route_113 = out_107 + out_108 + out_110 + out_112\n",
    "        \n",
    "        out_114 = conv_layer_114(out_113)\n",
    "        out_115 = conv_layer_115(out_114)\n",
    "        out_116 = conv_layer_116(out_115)\n",
    "        out_117 = conv_layer_117(out_116)\n",
    "        \n",
    "        out_118 = Upsample_layer_118(out_117)\n",
    "        \n",
    "        out_120 = conv_layer_120(layer_120_in)\n",
    "        \n",
    "        route_121 = out_118 + out_120\n",
    "        \n",
    "        \n",
    "        out_122 = conv_layer_122(layer_121_in)\n",
    "        out_123 = conv_layer_123(layer_122_in)\n",
    "        out_124 = conv_layer_124(layer_123_in)\n",
    "        out_125 = conv_layer_125(layer_124_in)\n",
    "        out_126 = conv_layer_126(layer_125_in)\n",
    "        out_127 = conv_layer_127(layer_126_in)\n",
    "        \n",
    "        out_128 = Upsample_layer_128(out_127)\n",
    "        \n",
    "        out_130 = conv_layer_130(layer_130_in)\n",
    "        \n",
    "        route_131 = out_128 + out_130\n",
    "        \n",
    "        \n",
    "        out_132 = conv_layer_132(layer_131_in)\n",
    "        out_133 = conv_layer_133(layer_132_in)\n",
    "        out_134 = conv_layer_134(layer_133_in)\n",
    "        out_135 = conv_layer_135(layer_134_in)\n",
    "        out_136 = conv_layer_136(layer_135_in)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return out_136, out_126, out_116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_v4_head(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.conv_layer_137 = Conv_Layer_box(128, 256, kernel_size=3, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        #pending: Linear activation function?\n",
    "        self.conv_layer_138 = Conv_Layer_box(256, 255, kernel_size=1, stride = 1, activation_func = \"ReLU\", batch_normalization = True)\n",
    "        #139 - YOLO layer\n",
    "        \n",
    "        \n",
    "        self.conv_layer_141 = Conv_Layer_box(128, 256, kernel_size=3, stride = 2, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_143 = Conv_Layer_box(256, 256, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_144 = Conv_Layer_box(256, 512, kernel_size=3, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_145 = Conv_Layer_box(512, 256, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_146 = Conv_Layer_box(256, 512, kernel_size=3, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_147 = Conv_Layer_box(512, 256, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_148 = Conv_Layer_box(256, 512, kernel_size=3, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_149 = Conv_Layer_box(512, 255, kernel_size=1, stride = 1, activation_func = \"ReLU\", batch_normalization = True)\n",
    "        #150 - YOLO layer\n",
    "        self.conv_layer_152 = Conv_Layer_box(256, 512, kernel_size=3, stride = 2, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_154 = Conv_Layer_box(512, 512, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_155 = Conv_Layer_box(512, 1024, kernel_size=3, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_156 = Conv_Layer_box(1024, 512, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_157 = Conv_Layer_box(512, 1024, kernel_size=3, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_158 = Conv_Layer_box(1024, 512, kernel_size=1, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_159 = Conv_Layer_box(512, 1024, kernel_size=3, stride = 1, activation_func = \"Leaky\", batch_normalization = True)\n",
    "        self.conv_layer_160 = Conv_Layer_box(1024, 255, kernel_size=1, stride = 1, activation_func = \"ReLU\", batch_normalization = True)\n",
    "        #161 - YOLO layer\n",
    "        \n",
    "    def forward(self, layer_136_out, layer_126_out, layer_116_out):\n",
    "        out_137 = self.conv_layer_137(layer_136_out)\n",
    "        out_138 = self.conv_layer_138(out_137)\n",
    "        #139 - YOLO layer\n",
    "        \n",
    "        out_141 = self.conv_layer_141(layer_136_out)\n",
    "        route_142 = out_141 + layer_126_out\n",
    "        out_143 = self.conv_layer_143(route_142)\n",
    "        out_144 = self.conv_layer_144(out_143)\n",
    "        \n",
    "        out_145 = self.conv_layer_145(out_144)\n",
    "        out_146 = self.conv_layer_146(out_145)\n",
    "        out_147 = self.conv_layer_147(out_146)\n",
    "        out_148 = self.conv_layer_148(out_147)\n",
    "        \n",
    "        out_149 = self.conv_layer_149(out_148)\n",
    "        #150 - YOLO layer\n",
    "        \n",
    "        out_152 = self.conv_layer_152(out_147)\n",
    "        route_153 = out_152 + layer_116_out\n",
    "        \n",
    "        \n",
    "        out_154 = self.conv_layer_154(route_153)\n",
    "        \n",
    "        out_155 = self.conv_layer_155(out_154)\n",
    "        out_156 = self.conv_layer_156(out_155)\n",
    "        out_157 = self.conv_layer_157(out_156)\n",
    "        out_158 = self.conv_layer_158(out_157)\n",
    "        \n",
    "        out_159 = self.conv_layer_159(out_158)\n",
    "        \n",
    "        \n",
    "        out_160 = self.conv_layer_160(out_159)\n",
    "        #161 - YOLO layer\n",
    "        \n",
    "        return ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_v4_Module(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YOLO_v4_Module, self).__init__()\n",
    "        #self.input_size = input_size\n",
    "        #self.output_size = output_size\n",
    "\n",
    "        \n",
    "        self.downsample_layer_1 = nn.Sequential(\n",
    "            nn.Identity()\n",
    "            nn.Conv2d(64, 32, kernel_size=1),\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.conv_layer_2 = nn.Conv2d(192, 128, kernel_size=1)\n",
    "        \n",
    "        self.conv_layer_3 = nn.Conv2d(192, 128, kernel_size=1)\n",
    "        self.conv_layer_4 = nn.Conv2d(128, 256, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_5 = nn.Conv2d(256, 256, kernel_size=1)\n",
    "        self.layer_6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.conv_layer_7 = nn.Conv2d(512, 256, kernel_size=1)\n",
    "        self.conv_layer_8 = nn.Conv2d(256, 512, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_9 = nn.Conv2d(512, 256, kernel_size=1)\n",
    "        self.conv_layer_10 = nn.Conv2d(256, 512, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_11 = nn.Conv2d(512, 256, kernel_size=1)\n",
    "        self.conv_layer_12 = nn.Conv2d(256, 512, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_13 = nn.Conv2d(512, 256, kernel_size=1)\n",
    "        self.conv_layer_14 = nn.Conv2d(256, 512, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_15 = nn.Conv2d(512, 512, kernel_size=1)\n",
    "        self.layer_16 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=(1,1)),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.conv_layer_17 = nn.Conv2d(1024, 512, kernel_size=1)\n",
    "        self.conv_layer_18 = nn.Conv2d(512, 1024, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_19 = nn.Conv2d(1024, 512, kernel_size=1)\n",
    "        self.conv_layer_20 = nn.Conv2d(512, 1024, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_21 = nn.Conv2d(1024, 1024, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_22 = nn.Conv2d(1024, 1024, kernel_size=3, stride=2, padding=(1,1))\n",
    "        self.conv_layer_23 = nn.Conv2d(1024, 1024, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_24 = nn.Conv2d(1024, 1024, kernel_size=3, padding=(1,1))\n",
    "        \n",
    "        self.fc1 = nn.Linear(7 * 7 * 1024, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 7 * 7 * 30)\n",
    "    def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.conv_layer_3(out)\n",
    "        out = self.conv_layer_4(out)\n",
    "        out = self.conv_layer_5(out)\n",
    "        out = self.layer_6(out)\n",
    "        out = self.conv_layer_7(out)\n",
    "        out = self.conv_layer_8(out)\n",
    "        out = self.conv_layer_9(out)\n",
    "        out = self.conv_layer_10(out)\n",
    "        out = self.conv_layer_11(out)\n",
    "        out = self.conv_layer_12(out)\n",
    "        out = self.conv_layer_13(out)\n",
    "        out = self.conv_layer_14(out)\n",
    "        out = self.conv_layer_15(out)\n",
    "        out = self.layer_16(out)\n",
    "        out = self.conv_layer_17(out)\n",
    "        out = self.conv_layer_18(out)\n",
    "        out = self.conv_layer_19(out)\n",
    "        out = self.conv_layer_20(out)\n",
    "        out = self.conv_layer_21(out)\n",
    "        out = self.conv_layer_22(out)\n",
    "        out = self.conv_layer_23(out)\n",
    "        out = self.conv_layer_24(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
