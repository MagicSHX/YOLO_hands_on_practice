{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from __future__ import division\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "cfgfile = \"C:/Users/HX/Desktop/yolov4.cfg\"\n",
    "model_file_path = \"Model/model.pt\"\n",
    "TL_model_file_path = \"Model/TL_model.pt\"\n",
    "\n",
    "def read_cfg_file(cfgfile):\n",
    "    file = open(cfgfile, 'r')\n",
    "    lines = file.read().split('\\n')\n",
    "\n",
    "    layer_type = []\n",
    "    layer_details = []\n",
    "    current_layer_details = {}\n",
    "    for line in lines:\n",
    "        #print(line)\n",
    "        if line == '':\n",
    "            continue\n",
    "        elif line[0] == '#':\n",
    "            continue\n",
    "        else:\n",
    "            if (line[0] == '['):\n",
    "                layer_type.append(line[1 : -1])\n",
    "                if current_layer_details != {}:\n",
    "                    layer_details.append(current_layer_details)\n",
    "                    current_layer_details = {}\n",
    "            else:\n",
    "                current_layer_details.update([(line.split(\"=\")[0].rstrip(), line.split(\"=\")[1].lstrip())])\n",
    "    layer_details.append(current_layer_details)\n",
    "    return layer_type, layer_details\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * torch.tanh(F.softplus(x))\n",
    "        return x\n",
    "\n",
    "class Conv_Layer_box(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride, activation_func, batch_normalization):\n",
    "        super().__init__()\n",
    "        padding = (int((kernel_size - 1)/2), int((kernel_size - 1)/2))\n",
    "        #TBC: linear\n",
    "        dict_activation_func = {\"ReLU\": nn.ReLU(inplace=False),\n",
    "                                \"linear\": nn.ReLU(inplace=False),\n",
    "                                \"leaky\": nn.LeakyReLU(0.1, inplace=False),\n",
    "                                \"mish\": Mish()\n",
    "                               }\n",
    "        \n",
    "        if batch_normalization == True:\n",
    "            bias = False\n",
    "        else:\n",
    "            bias = True\n",
    "        self.conv_box = nn.ModuleList()\n",
    "        self.conv_box.append(nn.Conv2d(in_channel, out_channel, kernel_size, stride, padding, bias = bias))\n",
    "        if batch_normalization == True:\n",
    "            self.conv_box.append(nn.BatchNorm2d(out_channel))\n",
    "        self.conv_box.append(dict_activation_func[activation_func])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.conv_box:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "class Maxpool_pad_Layer_box(nn.Module):\n",
    "    def __init__(self, maxpool_size):\n",
    "        super().__init__()\n",
    "        self.maxpool_size = maxpool_size\n",
    "        #why there are 2 padding??????????????\n",
    "        self.pad_1 = int((self.maxpool_size - 1) / 2)\n",
    "        self.pad_2 = self.pad_1\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, (self.pad_1, self.pad_2, self.pad_1, self.pad_2), mode='replicate')\n",
    "        x = F.max_pool2d(x, self.maxpool_size, stride=1)\n",
    "        return x\n",
    "    \n",
    "class Upsample_layer(nn.Module):\n",
    "    def __init__(self, stride):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch, channel, height, width = x.data.size()\n",
    "        x = x.view(batch, channel, height, 1, width, 1).expand(batch, channel, height, self.stride, width, self.stride).clone()\n",
    "        x = x.contiguous().view(batch, channel, height * self.stride, width * self.stride).clone()\n",
    "        return x\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "class shortcut(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "class route(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_length(a_1, a_2, b_1, b_2):\n",
    "    if a_1 <=b_1 and a_2 >= b_1:\n",
    "        return (min(a_2, b_2) - b_1)\n",
    "    elif a_1 <=b_1 and a_2 <= b_1:\n",
    "        return 0\n",
    "    else:\n",
    "        return cross_length(b_1, b_2, a_1, a_2)\n",
    "\n",
    "def IoU(x_GT, y_GT, h_GT, w_GT, x_PD, y_PD, h_PD, w_PD):\n",
    "    area_of_I = cross_length(x_GT, x_GT + h_GT, x_PD, x_PD + h_PD) * cross_length(y_GT, y_GT + h_GT, y_PD, y_PD + h_PD)\n",
    "    area_of_U = h_GT * w_GT + h_PD * w_PD - area_of_I\n",
    "    return area_of_I / area_of_U\n",
    "\n",
    "\n",
    "\n",
    "def axis_conversion(x_centre, y_centre, h, w):\n",
    "    return (x_centre - h / 2, y_centre - w / 2, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.5, 4.5, 3, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25/(64)\n",
    "axis_conversion(6, 6, 3,3)\n",
    "#IoU(11,11,8,8,12,12,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yolo_input = np.array([1.0 for i in range(255 * 76 * 76 * 2)]).reshape(2, 255, 76, 76)\n",
    "Yolo_input = torch.from_numpy(Yolo_input)\n",
    "#input[:,:,0,0] = 2\n",
    "#input[:,:,0,0]\n",
    "anchors = [12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401]\n",
    "mask = [0, 1, 2]\n",
    "classes = 80\n",
    "input_image_size = 608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_on_Matrix_x = torch.from_numpy(np.array([[i for j in range(19)] for i in range(19)]))\n",
    "#add_on_Matrix_y = [[i for i in range(19)] for j in range(19)]\n",
    "#add_on_Matrix_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n#Yolo_run_layer = Yolo(anchors, mask, classes, input_image_size)\\n\\n#b_x, b_y, b_w, b_h, objective_p, class_p = Yolo_run_layer(Yolo_input)\\n#combined_yolo_output = torch.cat((b_x, b_y, b_w, b_h, objective_p, class_p), 2)\\n\\nYolo_input = np.array([1.0 for i in range(255 * 76 * 76 * 2)]).reshape(2, 255, 76, 76)\\nYolo_input = torch.from_numpy(Yolo_input)\\ntarget = np.array([0 for i in range(3 * 76 * 76 * 85)])\\ninput_tensor = Yolo_input\\noutput_tensor = torch.Tensor(target)\\n\\nlearning_rate = 0.08\\nepoch_size = 5\\nsteps_for_printing_out_loss = 1\\n\\nYOLO_Module_WIP = Yolo(anchors, mask, classes, input_image_size)\\nYOLO_Module_WIP.cuda()\\n#Model_WIP.to(device)\\nloss_functioin = nn.MSELoss()\\noptimizer = optim.SGD(YOLO_Module_WIP.parameters(), lr = learning_rate)\\n\\ninput = input_tensor.cuda()\\ntarget = output_tensor.cuda()\\n\\ndef training_model():\\n    for i in range(1, epoch_size + 1):\\n        optimizer.zero_grad()\\n        output = YOLO_Module_WIP(input.cuda())\\n        print(output.size())\\n        #b_x, b_y, b_w, b_h, objective_p, class_p = YOLO_v4_Module_WIP(input.cuda())\\n        #output = b_x\\n        loss = loss_functioin(output, target.reshape(output.size(0), output.size(1), output.size(2), output.size(3), output.size(4)))\\n        loss.backward()\\n        optimizer.step()\\n        if i % (steps_for_printing_out_loss) == 0:\\n            print('Loss (epoch: ' + str(i) + '): ' + str(loss.cpu().detach().numpy()))\\n    torch.save({'state_dict': YOLO_v4_Module_WIP.state_dict(),'optimizer': optimizer.state_dict()}, model_file_path)\\n\\ntraining_model()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Yolo(nn.Module):\n",
    "    def __init__(self, anchors, mask, classes, input_image_size):\n",
    "        super().__init__()\n",
    "        self.anchors = anchors\n",
    "        self.mask = mask\n",
    "        self.classes = classes\n",
    "        self.number_of_mask = len(mask)\n",
    "        self.input_image_size = input_image_size\n",
    "        #self.Sigmoid_layer = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        mask = self.mask\n",
    "        anchors = self.anchors\n",
    "        classes = self.classes\n",
    "        number_of_mask = self.number_of_mask\n",
    "        input_image_size = self.input_image_size\n",
    "        grid_size = int(input_image_size / x.size(2))\n",
    "        #print(grid_size)\n",
    "        #t_x = torch.from_numpy(np.array([0.0 for i in range(number_of_mask * x.size(0) * x.size(2) * x.size(3))]).reshape(number_of_mask * x.size(0), 1, x.size(2), x.size(3)))\n",
    "        t_x = [None for i in range(number_of_mask)]\n",
    "        t_y = [None for i in range(number_of_mask)]\n",
    "        t_w = [None for i in range(number_of_mask)]\n",
    "        t_h = [None for i in range(number_of_mask)]\n",
    "        objective_p = [None for i in range(number_of_mask)]\n",
    "        class_p = [None for i in range(number_of_mask)]\n",
    "        \n",
    "        #c_x = [i for i in range(x.size(2))]\n",
    "        #c_y = [i for i in range(x.size(2))]\n",
    "        \n",
    "        add_on_Matrix_x = torch.from_numpy(np.array([[i for j in range(x.size(2))] for i in range(x.size(2))])).cuda()\n",
    "        add_on_Matrix_y = torch.from_numpy(np.array([[i for i in range(x.size(2))] for j in range(x.size(2))])).cuda()\n",
    "        \n",
    "        b_x = [None for i in range(number_of_mask)]\n",
    "        b_y = [None for i in range(number_of_mask)]\n",
    "        b_w = [None for i in range(number_of_mask)]\n",
    "        b_h = [None for i in range(number_of_mask)]\n",
    "        \n",
    "        \n",
    "        anchor_shape_1 = int(len(anchors) / 2)\n",
    "        anchors = np.array(anchors).reshape(anchor_shape_1, 2)\n",
    "        \n",
    "        #print(anchors)\n",
    "        \n",
    "        p_w = [None for i in range(number_of_mask)]\n",
    "        p_h = [None for i in range(number_of_mask)]\n",
    "        \n",
    "        \n",
    "        for i in range(number_of_mask):\n",
    "            start_point = i * (5 + classes)\n",
    "            end_point = (i + 1) * (5 + classes)\n",
    "            p_w[i], p_h[i] = anchors[mask[i]]\n",
    "            #print(p_w)\n",
    "            #print(p_h)\n",
    "            \n",
    "            t_x[i] = x[:, (start_point + 0) : (start_point + 1), :, :].clone()\n",
    "            \n",
    "            t_y[i] = x[:, (start_point + 1) : (start_point + 2), :, :].clone()\n",
    "            t_w[i] = x[:, (start_point + 2) : (start_point + 3), :, :].clone()\n",
    "            t_h[i] = x[:, (start_point + 3) : (start_point + 4), :, :].clone()\n",
    "            objective_p[i] = x[:, (start_point + 4) : (start_point + 5), :, :].clone()\n",
    "            class_p[i] = x[:, (start_point + 5) : end_point, :, :].clone()\n",
    "            #print(type(t_x[i]))\n",
    "            \n",
    "            #print(F.sigmoid(t_x[i].clone()))\n",
    "            b_x[i] = torch.sigmoid(t_x[i].clone()) + add_on_Matrix_x\n",
    "            #print(b_x[i])\n",
    "            b_y[i] = torch.sigmoid(t_y[i].clone()) + add_on_Matrix_y\n",
    "            \n",
    "            #b_x[i][0, 0, :, :] = b_x[i][0, 0, :, :].clone()\n",
    "            #b_y[i][0, 0, :, :] = b_y[i][0, 0, :, :].clone()\n",
    "            \n",
    "            \"\"\"\n",
    "            print(t_x[i].size())\n",
    "            for m in range(x.size(2)):\n",
    "                for n in range(x.size(2)):\n",
    "                    b_x[i][:, :, c_x[m], c_y[n]] = c_x[m] + b_x[i][:, :, c_x[m], c_y[n]].clone()\n",
    "                    b_y[i][:, :, c_x[m], c_y[n]] = c_y[n] + b_y[i][:, :, c_x[m], c_y[n]].clone()\n",
    "            \"\"\"\n",
    "            #need to think whether need to use below 2 lines\n",
    "            b_x[i] = grid_size * b_x[i].clone()\n",
    "            b_y[i] = grid_size * b_y[i].clone()\n",
    "            b_w[i] = p_w[i] * torch.exp(t_w[i].clone())\n",
    "            b_h[i] = p_h[i] * torch.exp(t_h[i].clone())\n",
    "            \n",
    "            objective_p[i] = torch.sigmoid(objective_p[i].clone())\n",
    "            class_p[i] = torch.sigmoid(class_p[i].clone())\n",
    "            #torch.reshape(t_x[i])\n",
    "        \n",
    "        b_x = torch.stack(b_x).clone()\n",
    "        b_y = torch.stack(b_y).clone()\n",
    "        b_w = torch.stack(b_w).clone()\n",
    "        b_h = torch.stack(b_h).clone()\n",
    "        objective_p = torch.stack(objective_p).clone()\n",
    "        class_p = torch.stack(class_p).clone()\n",
    "        combined_yolo_output = torch.cat((b_x, b_y, b_w, b_h, objective_p, class_p), 2)\n",
    "        #return b_x, b_y, b_w, b_h, objective_p, class_p\n",
    "        #return combined_yolo_output\n",
    "        \n",
    "        \n",
    "        #b_x = torch.stack(b_x).clone()\n",
    "        return combined_yolo_output\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Yolo_run_layer = Yolo(anchors, mask, classes, input_image_size)\n",
    "\n",
    "#b_x, b_y, b_w, b_h, objective_p, class_p = Yolo_run_layer(Yolo_input)\n",
    "#combined_yolo_output = torch.cat((b_x, b_y, b_w, b_h, objective_p, class_p), 2)\n",
    "\n",
    "Yolo_input = np.array([1.0 for i in range(255 * 76 * 76 * 2)]).reshape(2, 255, 76, 76)\n",
    "Yolo_input = torch.from_numpy(Yolo_input)\n",
    "target = np.array([0 for i in range(3 * 76 * 76 * 85)])\n",
    "input_tensor = Yolo_input\n",
    "output_tensor = torch.Tensor(target)\n",
    "\n",
    "learning_rate = 0.08\n",
    "epoch_size = 5\n",
    "steps_for_printing_out_loss = 1\n",
    "\n",
    "YOLO_Module_WIP = Yolo(anchors, mask, classes, input_image_size)\n",
    "YOLO_Module_WIP.cuda()\n",
    "#Model_WIP.to(device)\n",
    "loss_functioin = nn.MSELoss()\n",
    "optimizer = optim.SGD(YOLO_Module_WIP.parameters(), lr = learning_rate)\n",
    "\n",
    "input = input_tensor.cuda()\n",
    "target = output_tensor.cuda()\n",
    "\n",
    "def training_model():\n",
    "    for i in range(1, epoch_size + 1):\n",
    "        optimizer.zero_grad()\n",
    "        output = YOLO_Module_WIP(input.cuda())\n",
    "        print(output.size())\n",
    "        #b_x, b_y, b_w, b_h, objective_p, class_p = YOLO_v4_Module_WIP(input.cuda())\n",
    "        #output = b_x\n",
    "        loss = loss_functioin(output, target.reshape(output.size(0), output.size(1), output.size(2), output.size(3), output.size(4)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % (steps_for_printing_out_loss) == 0:\n",
    "            print('Loss (epoch: ' + str(i) + '): ' + str(loss.cpu().detach().numpy()))\n",
    "    torch.save({'state_dict': YOLO_v4_Module_WIP.state_dict(),'optimizer': optimizer.state_dict()}, model_file_path)\n",
    "\n",
    "training_model()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo_TL(nn.Module):\n",
    "    def __init__(self, anchors, mask, classes, input_image_size):\n",
    "        super().__init__()\n",
    "        self.anchors = anchors\n",
    "        self.mask = mask\n",
    "        self.classes = classes\n",
    "        self.number_of_mask = len(mask)\n",
    "        self.input_image_size = input_image_size\n",
    "        #self.Sigmoid_layer = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        mask = self.mask\n",
    "        anchors = self.anchors\n",
    "        classes = self.classes\n",
    "        number_of_mask = self.number_of_mask\n",
    "        input_image_size = self.input_image_size\n",
    "        grid_size = int(input_image_size / x.size(2))\n",
    "        #print(grid_size)\n",
    "        #t_x = torch.from_numpy(np.array([0.0 for i in range(number_of_mask * x.size(0) * x.size(2) * x.size(3))]).reshape(number_of_mask * x.size(0), 1, x.size(2), x.size(3)))\n",
    "        t_x = [None for i in range(number_of_mask)]\n",
    "        t_y = [None for i in range(number_of_mask)]\n",
    "        t_w = [None for i in range(number_of_mask)]\n",
    "        t_h = [None for i in range(number_of_mask)]\n",
    "        objective_p = [None for i in range(number_of_mask)]\n",
    "        class_p = [None for i in range(number_of_mask)]\n",
    "        \n",
    "        #c_x = [i for i in range(x.size(2))]\n",
    "        #c_y = [i for i in range(x.size(2))]\n",
    "        \n",
    "        #add_on_Matrix_x = torch.from_numpy(np.array([[i for j in range(x.size(2))] for i in range(x.size(2))])).cuda()\n",
    "        #add_on_Matrix_y = torch.from_numpy(np.array([[i for i in range(x.size(2))] for j in range(x.size(2))])).cuda()\n",
    "        \n",
    "        b_x = [None for i in range(number_of_mask)]\n",
    "        b_y = [None for i in range(number_of_mask)]\n",
    "        b_w = [None for i in range(number_of_mask)]\n",
    "        b_h = [None for i in range(number_of_mask)]\n",
    "        \n",
    "        \n",
    "        anchor_shape_1 = int(len(anchors) / 2)\n",
    "        anchors = np.array(anchors).reshape(anchor_shape_1, 2)\n",
    "        \n",
    "        #print(anchors)\n",
    "        \n",
    "        #p_w = [None for i in range(number_of_mask)]\n",
    "        #p_h = [None for i in range(number_of_mask)]\n",
    "        \n",
    "        \n",
    "        for i in range(number_of_mask):\n",
    "            start_point = i * (5 + classes)\n",
    "            end_point = (i + 1) * (5 + classes)\n",
    "            #p_w[i], p_h[i] = anchors[mask[i]]\n",
    "            #print(p_w)\n",
    "            #print(p_h)\n",
    "            \n",
    "            t_x[i] = x[:, (start_point + 0) : (start_point + 1), :, :].clone()\n",
    "            \n",
    "            t_y[i] = x[:, (start_point + 1) : (start_point + 2), :, :].clone()\n",
    "            t_w[i] = x[:, (start_point + 2) : (start_point + 3), :, :].clone()\n",
    "            t_h[i] = x[:, (start_point + 3) : (start_point + 4), :, :].clone()\n",
    "            objective_p[i] = x[:, (start_point + 4) : (start_point + 5), :, :].clone()\n",
    "            class_p[i] = x[:, (start_point + 5) : end_point, :, :].clone()\n",
    "\n",
    "            b_x[i] = torch.sigmoid(t_x[i].clone())\n",
    "            b_y[i] = torch.sigmoid(t_y[i].clone())\n",
    "\n",
    "            b_w[i] = torch.exp(t_w[i].clone())\n",
    "            b_h[i] = torch.exp(t_h[i].clone())\n",
    "            \n",
    "            objective_p[i] = torch.sigmoid(objective_p[i].clone())\n",
    "            class_p[i] = torch.sigmoid(class_p[i].clone())\n",
    "            #torch.reshape(t_x[i])\n",
    "        \n",
    "        b_x = torch.stack(b_x).clone()\n",
    "        b_y = torch.stack(b_y).clone()\n",
    "        b_w = torch.stack(b_w).clone()\n",
    "        b_h = torch.stack(b_h).clone()\n",
    "        objective_p = torch.stack(objective_p).clone()\n",
    "        class_p = torch.stack(class_p).clone()\n",
    "        combined_yolo_output = torch.cat((b_x, b_y, b_w, b_h, objective_p, class_p), 2)\n",
    "        #return b_x, b_y, b_w, b_h, objective_p, class_p\n",
    "        #return combined_yolo_output\n",
    "        \n",
    "        \n",
    "        #b_x = torch.stack(b_x).clone()\n",
    "        return combined_yolo_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_yolo_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n",
      "162\n",
      "{'batch_normalize': '1', 'filters': '64', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'mish'}\n"
     ]
    }
   ],
   "source": [
    "layer_type, layer_details = read_cfg_file(cfgfile)\n",
    "\n",
    "net_layer = layer_details[0]\n",
    "\n",
    "layer_type = layer_type[1:]\n",
    "layer_details = layer_details[1:]\n",
    "\n",
    "print(len(layer_type))\n",
    "print(len(layer_details))\n",
    "print(layer_details[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nanchor = 3\\n#yolo_layer = 3\\noutput = (19 ** 2) * (1 + 4 + 16)\\nanchor * output\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "anchor = 3\n",
    "#yolo_layer = 3\n",
    "output = (19 ** 2) * (1 + 4 + 16)\n",
    "anchor * output\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build module for entire YOLO\n",
    "class YOLO_v4_model(nn.Module):\n",
    "    def __init__(self, layer_details, layer_type):\n",
    "        super(YOLO_v4_model, self).__init__()\n",
    "        self.all_layers = nn.ModuleList()\n",
    "        all_layers = self.all_layers\n",
    "        self.layer_details = layer_details\n",
    "        self.layer_type = layer_type\n",
    "\n",
    "        for i in range(len(layer_type)):\n",
    "            if layer_type[i] == 'convolutional':\n",
    "                #print(layer_details[i])\n",
    "                #print(i)\n",
    "                try:\n",
    "                    if int(layer_details[i]['batch_normalize']) == 1:\n",
    "                        batch_normalize = True\n",
    "                    else:\n",
    "                        batch_normalize = False\n",
    "                except:\n",
    "                    batch_normalize = False\n",
    "                if i == 0:\n",
    "                    in_channel = 3\n",
    "                else:\n",
    "                    in_channel = None\n",
    "                    if layer_type[i - 1] == 'convolutional':\n",
    "                        skip_step = [0]\n",
    "                    elif layer_type[i - 1] == 'shortcut':\n",
    "                        skip_step = [int(layer_details[i - 1]['from'])]\n",
    "                    elif layer_type[i - 1] == 'route':\n",
    "                        skip_step = layer_details[i - 1]['layers'].split(\",\")\n",
    "                        \n",
    "                    \"\"\"\n",
    "                    if skip_step > 0:\n",
    "                        in_channel = int(layer_details[skip_step]['filters'])\n",
    "                    else:\n",
    "                        in_channel = int(layer_details[i - 1 + skip_step]['filters'])\n",
    "                    \"\"\"\n",
    "                    for SS in skip_step:\n",
    "                        SS = int(SS)\n",
    "                        if SS > 0:\n",
    "                            if in_channel == None:\n",
    "                                in_channel = int(layer_details[SS]['filters'])\n",
    "                            else:\n",
    "                                in_channel += int(layer_details[SS]['filters'])\n",
    "                        else:\n",
    "                            if in_channel == None:\n",
    "                                in_channel = int(layer_details[i - 1 + SS]['filters'])\n",
    "                            else:\n",
    "                                in_channel += int(layer_details[i - 1 + SS]['filters'])\n",
    "                        \n",
    "                out_channel = int(layer_details[i]['filters'])\n",
    "                kernel_size = int(layer_details[i]['size'])\n",
    "                stride = int(layer_details[i]['stride'])\n",
    "                pad = int(layer_details[i]['pad'])\n",
    "                activation_func = layer_details[i]['activation']\n",
    "                layer = Conv_Layer_box(in_channel, out_channel, kernel_size, stride, activation_func, batch_normalize)\n",
    "                #print(layer)\n",
    "            elif layer_type[i] == 'maxpool':\n",
    "                layer_details[i].update([('filters', layer_details[i - 1]['filters'])])\n",
    "                maxpool_size = int(layer_details[i]['size'])\n",
    "                #print(maxpool_size)\n",
    "                layer = Maxpool_pad_Layer_box(maxpool_size)\n",
    "                #print(layer)\n",
    "            elif layer_type[i] == 'upsample':\n",
    "                layer_details[i].update([('filters', layer_details[i - 1]['filters'])])\n",
    "                stride = int(layer_details[i]['stride'])\n",
    "                layer = Upsample_layer(stride)\n",
    "            elif layer_type[i] == 'yolo':\n",
    "                #print(\"yolo\")\n",
    "                anchors = [int(x) for x in layer_details[i]['anchors'].split(\",\")]\n",
    "                \n",
    "                mask = [int(x) for x in layer_details[i]['mask'].split(\",\")]\n",
    "                classes = int(layer_details[i]['classes'])\n",
    "                #input image size = 608 for now\n",
    "                layer = Yolo(anchors, mask, classes, input_image_size)\n",
    "                #print(anchors)\n",
    "                #print(classes)\n",
    "                #print(input_image_size)\n",
    "                #continue\n",
    "            elif layer_type[i] == 'shortcut':\n",
    "                skip_step = int(layer_details[i]['from'])\n",
    "                layer_details[i].update([('filters', layer_details[i + skip_step]['filters'])])\n",
    "                layer = shortcut()\n",
    "            elif layer_type[i] == 'route':\n",
    "                try:\n",
    "                    skip_step = int(layer_details[i]['layers'].split(\",\")[0])\n",
    "                except:\n",
    "                    skip_step = int(layer_details[i]['layers'])\n",
    "                #print(skip_step)\n",
    "                if skip_step > 0:\n",
    "                    layer_details[i].update([('filters', layer_details[skip_step]['filters'])])\n",
    "                else:\n",
    "                    layer_details[i].update([('filters', layer_details[i + skip_step]['filters'])])\n",
    "                layer = route()\n",
    "            elif layer_type[i] == 'net':\n",
    "                #print(\"net\")\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            all_layers.append(layer)\n",
    "        global all_layerrr\n",
    "        all_layerrr = all_layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        all_layers = self.all_layers\n",
    "        layers_output = [None for i in range(len(layer_type))]\n",
    "        for i in range(len(layer_type)):\n",
    "            #print(i)\n",
    "            if i == 0:\n",
    "                layers_output[i] = all_layers[i](x)\n",
    "                continue\n",
    "                \n",
    "            elif layer_type[i] == 'yolo':\n",
    "                layers_output[i] = all_layers[i](layers_output[i - 1])\n",
    "                continue\n",
    "            elif layer_type[i] == 'convolutional' or layer_type[i] == 'maxpool' or layer_type[i] == 'upsample' or layer_type[i] == 'yolo':\n",
    "                layers_output[i] = all_layers[i](layers_output[i - 1])\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    print(\"i: \" + str(i) + str(layers_output[i].size()))\n",
    "                except:\n",
    "                    print(\"go\")\n",
    "                \"\"\"\n",
    "                continue\n",
    "            elif layer_type[i] == 'shortcut':\n",
    "                skip_step = [int(layer_details[i]['from'])]\n",
    "            elif layer_type[i] == 'route':\n",
    "                skip_step = layer_details[i]['layers'].split(\",\")\n",
    "            for SS in skip_step:\n",
    "                SS = int(SS)\n",
    "                #print(\"SS\" + str(i) + str(SS))\n",
    "                #print(skip_step)\n",
    "                \n",
    "                #print(SS)\n",
    "                #print(layers_output[i])\n",
    "                #print(layers_output[i - 1 + SS])\n",
    "                \n",
    "                if SS > 0:\n",
    "                    if layers_output[i] == None:\n",
    "                        #print(layers_output[SS].size())\n",
    "                        layers_output[i] = layers_output[SS]\n",
    "                    else:\n",
    "                        #print(layers_output[SS].size())\n",
    "                        layers_output[i] = torch.cat((layers_output[i], layers_output[SS]), 1)\n",
    "                else:\n",
    "                    #print(i + SS)\n",
    "                    if layers_output[i] == None:\n",
    "                        #print(layers_output[i + SS].size())\n",
    "                        layers_output[i] = layers_output[i + SS]\n",
    "                    else:\n",
    "                        \n",
    "                        #print(layers_output[i + SS].size())\n",
    "                        layers_output[i] = torch.cat((layers_output[i], layers_output[i + SS]), 1)\n",
    "            \"\"\"\n",
    "            try:\n",
    "                print(\"i: \" + str(i) + str(layers_output[i].size()))\n",
    "            except:\n",
    "                print(\"go\")\n",
    "            \"\"\"\n",
    "        #print(layers_output[138].size())\n",
    "        return layers_output[137], layers_output[148], layers_output[159]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input = np.array([1 for i in range(608 * 608 * 3 * 1)]).reshape(1, 3, 608, 608)\n",
    "#target = np.array([0 for i in range(7 * 7 * 30)])\n",
    "target = np.array([0 for i in range(3 * 19 * 19 * 85)])\n",
    "\n",
    "input_tensor = torch.Tensor(input)\n",
    "output_tensor = torch.Tensor(target)\n",
    "\n",
    "#x = np.array([1 for i in range(608 * 608 * 3)]).reshape(1, 3, 608, 608)\n",
    "#x = torch.tensor(x)\n",
    "\n",
    "learning_rate = 0.08\n",
    "epoch_size = 2\n",
    "steps_for_printing_out_loss = 1\n",
    "\n",
    "YOLO_v4_Module_WIP = YOLO_v4_model(layer_details, layer_type)\n",
    "YOLO_v4_Module_WIP.cuda()\n",
    "\n",
    "\n",
    "\n",
    "#YOLO_v4_Module_WIP.load_state_dict(torch.load(\"D:/Installation/yolov4.pt\"))\n",
    "\n",
    "#YOLO_v4_Module_WIP.load_weights(\"â€ªD:/Installation/yolov4.weights\")\n",
    "#Model_WIP.to(device)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(YOLO_v4_Module_WIP.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for name, param in YOLO_v4_Module_WIP.named_parameters():\n",
    "    print('name: ', name)\n",
    "    print(type(param))\n",
    "    print('param.shape: ', param.shape)\n",
    "    print('param.requires_grad: ', param.requires_grad)\n",
    "    print('=====')\n",
    "#transfer learning:\n",
    "\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name in ['fc.weight', 'fc.bias']:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\"\"\"\n",
    "#YOLO_v4_Module_WIP.load_state_dict(torch.load(\"C:/Users/HX/Desktop/model.pt\")['state_dict'])\n",
    "#YOLO_v4_Module_WIP.eval()\n",
    "input = input_tensor.cuda()\n",
    "target = output_tensor.cuda()\n",
    "\n",
    "def training_model():\n",
    "    for i in range(1, epoch_size + 1):\n",
    "        optimizer.zero_grad()\n",
    "        output = YOLO_v4_Module_WIP(input.cuda())\n",
    "        #print(output.size())\n",
    "        #b_x, b_y, b_w, b_h, objective_p, class_p = YOLO_v4_Module_WIP(input.cuda())\n",
    "        #output = b_x\n",
    "        #loss = loss_function(output, target.reshape(output.size(0), output.size(1), output.size(2), output.size(3)))\n",
    "        global output_tensor\n",
    "        output_tensor = output\n",
    "        loss = loss_function(output, target.reshape(output.size(0), output.size(1), output.size(2), output.size(3), output.size(4)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % (steps_for_printing_out_loss) == 0:\n",
    "            print('Loss (epoch: ' + str(i) + '): ' + str(loss.cpu().detach().numpy()))\n",
    "    #torch.save({'state_dict': YOLO_v4_Module_WIP.state_dict(),'optimizer': optimizer.state_dict()}, model_file_path)\n",
    "\n",
    "\n",
    "#training_model()\n",
    "#torch.save({'output': output_tensor}, 'Model/output.pt')\n",
    "#YOLO_v4_Module_WIP.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYOLO_v4_Module_WIP = YOLO_v4_model(layer_details, layer_type)\\nYOLO_v4_Module_WIP.cuda()\\nYOLO_v4_Module_WIP.load_state_dict(torch.load(\"C:/Users/HX/Desktop/model.pt\")[\\'state_dict\\'])\\nYOLO_v4_Module_WIP.eval()\\n    \\nfor current_batch_no in range(3774, len(image_path_list) // batch_size):\\n    input = image_reader(image_path_list[batch_size * current_batch_no: batch_size * (current_batch_no + 1)])\\n    input_tensor = torch.Tensor(input).cuda()\\n    #print(input.shape)\\n    output_137, output_148, output_159 = running_YOLO_v4_model(input_tensor)\\n    print(output_137.shape)\\n    file_name = \\'F:/FlyAI/TL_input_data/\\' + str(current_batch_no) + \\'.pt\\'\\n    torch.save({\\'output_137\\': output_137, \\'output_148\\': output_148, \\'output_159\\': output_159}, file_name)\\n    \\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_image_folder = \"F:/FlyAI/UnderwaterDetection_roundA/train-A/image/\"\n",
    "batch_size = 1\n",
    "import math\n",
    "import glob\n",
    "image_path_list = glob.glob(training_data_image_folder + \"*.jpg\")\n",
    "\n",
    "batch_no = math.ceil(len(image_path_list) / batch_size)\n",
    "print(batch_no)\n",
    "\n",
    "\n",
    "\n",
    "def image_reader(image_path_list):\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    final_output_array = []\n",
    "    for image_path in image_path_list:\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize((608, 608))\n",
    "        image = np.array(image)\n",
    "        image_array = np.array([0 for i in range(3 * 608 * 608)]).reshape(3, 608, 608)\n",
    "        for i in range(3):\n",
    "            image_array[i] = image[:, :, i]\n",
    "        #print(image_array.shape)\n",
    "        final_output_array.append(image_array)\n",
    "    return np.array(final_output_array)\n",
    "\n",
    "\n",
    "def running_YOLO_v4_model(input):\n",
    "\n",
    "    output = YOLO_v4_Module_WIP(input_tensor)\n",
    "    return output\n",
    "\n",
    "#########convert original image into output from YOLOv4\n",
    "\"\"\"\n",
    "YOLO_v4_Module_WIP = YOLO_v4_model(layer_details, layer_type)\n",
    "YOLO_v4_Module_WIP.cuda()\n",
    "YOLO_v4_Module_WIP.load_state_dict(torch.load(\"C:/Users/HX/Desktop/model.pt\")['state_dict'])\n",
    "YOLO_v4_Module_WIP.eval()\n",
    "    \n",
    "for current_batch_no in range(3774, len(image_path_list) // batch_size):\n",
    "    input = image_reader(image_path_list[batch_size * current_batch_no: batch_size * (current_batch_no + 1)])\n",
    "    input_tensor = torch.Tensor(input).cuda()\n",
    "    #print(input.shape)\n",
    "    output_137, output_148, output_159 = running_YOLO_v4_model(input_tensor)\n",
    "    print(output_137.shape)\n",
    "    file_name = 'F:/FlyAI/TL_input_data/' + str(current_batch_no) + '.pt'\n",
    "    torch.save({'output_137': output_137, 'output_148': output_148, 'output_159': output_159}, file_name)\n",
    "    \n",
    "\"\"\"\n",
    "#torch.save({'output_137': output_137}, 'Model/output.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_layerrr\n",
    "\n",
    "class transfer_learning_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.anchors = [12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401]\n",
    "        self.mask_a = [0, 1, 2]\n",
    "        self.mask_b = [3, 4, 5]\n",
    "        self.mask_c = [6, 7, 8]\n",
    "        #self.TL_model_list = nn.ModuleList()\n",
    "        #TL_model_list.append(Conv_Layer_box(in_channel = 256, out_channel = 255, kernel_size = 1, stride = 1, activation_func = 'linear', batch_normalize = False))\n",
    "        self.Conv_Layer_76_a = Conv_Layer_box(in_channel = 256, out_channel = 255, kernel_size = 1, stride = 1, activation_func = 'linear', batch_normalization = False)\n",
    "        self.Sigmoid_layer_76 = nn.Sigmoid()\n",
    "        self.Conv_Layer_76_b = Conv_Layer_box(in_channel = 255, out_channel = 27, kernel_size = 1, stride = 1, activation_func = 'linear', batch_normalization = False)\n",
    "        #self.Yolo_Layer_76 = Yolo(self.anchors, self.mask_a, classes = 4, input_image_size = 608)\n",
    "        self.Yolo_Layer_76 = Yolo_TL(self.anchors, self.mask_a, classes = 4, input_image_size = 608)\n",
    "        \n",
    "        self.Conv_Layer_38_a = Conv_Layer_box(in_channel = 512, out_channel = 255, kernel_size = 1, stride = 1, activation_func = 'linear', batch_normalization = False)\n",
    "        self.Sigmoid_layer_38 = nn.Sigmoid()\n",
    "        self.Conv_Layer_38_b = Conv_Layer_box(in_channel = 255, out_channel = 27, kernel_size = 1, stride = 1, activation_func = 'linear', batch_normalization = False)\n",
    "        #self.Yolo_Layer_38 = Yolo(self.anchors, self.mask_b, classes = 4, input_image_size = 608)\n",
    "        self.Yolo_Layer_38 = Yolo_TL(self.anchors, self.mask_b, classes = 4, input_image_size = 608)\n",
    "        \n",
    "        self.Conv_Layer_19_a = Conv_Layer_box(in_channel = 1024, out_channel = 255, kernel_size = 1, stride = 1, activation_func = 'linear', batch_normalization = False)\n",
    "        self.Sigmoid_layer_19 = nn.Sigmoid()\n",
    "        self.Conv_Layer_19_b = Conv_Layer_box(in_channel = 255, out_channel = 27, kernel_size = 1, stride = 1, activation_func = 'linear', batch_normalization = False)\n",
    "        #self.Yolo_Layer_19 = Yolo(self.anchors, self.mask_c, classes = 4, input_image_size = 608)\n",
    "        self.Yolo_Layer_19 = Yolo_TL(self.anchors, self.mask_c, classes = 4, input_image_size = 608)\n",
    "        \n",
    "    def forward(self, layer_137_out, layer_148_out, layer_159_out):\n",
    "        out_76_1 = self.Conv_Layer_76_a(layer_137_out)\n",
    "        out_76_1 = self.Sigmoid_layer_76(out_76_1)\n",
    "        out_76_1 = self.Conv_Layer_76_b(out_76_1)\n",
    "        out_76_1 = self.Yolo_Layer_76(out_76_1)\n",
    "        \n",
    "        out_38_1 = self.Conv_Layer_38_a(layer_148_out)\n",
    "        out_38_1 = self.Sigmoid_layer_38(out_38_1)\n",
    "        out_38_1 = self.Conv_Layer_38_b(out_38_1)\n",
    "        out_38_1 = self.Yolo_Layer_38(out_38_1)\n",
    "        \n",
    "        out_19_1 = self.Conv_Layer_19_a(layer_159_out)\n",
    "        out_19_1 = self.Sigmoid_layer_19(out_19_1)\n",
    "        out_19_1 = self.Conv_Layer_19_b(out_19_1)\n",
    "        out_19_1 = self.Yolo_Layer_19(out_19_1)\n",
    "        #another option: only use 1 conv layer b, and Yolo layer\n",
    "        return out_76_1, out_38_1, out_19_1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['holothurian',\n",
       " 0,\n",
       " 225.46666666666667,\n",
       " 233.62962962962962,\n",
       " 265.3666666666667,\n",
       " 322.5777777777778,\n",
       " '000001',\n",
       " 1920,\n",
       " 1080,\n",
       " 39.900000000000006,\n",
       " 88.94814814814816,\n",
       " 3,\n",
       " 15,\n",
       " 17,\n",
       " 0.33854166666666785,\n",
       " 0.38148148148147953,\n",
       " 0.08692810457516341,\n",
       " 0.22181583079338693]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from PIL import ImageTk, Image\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "#import training data\n",
    "\n",
    "round_A_data_folder = \"F:/FlyAI/UnderwaterDetection_roundA/\"\n",
    "round_A_image_folder = round_A_data_folder + \"train-A/image/\"\n",
    "round_A_box_folder = round_A_data_folder + \"train-A/box/\"\n",
    "\n",
    "box_file_path_list = glob.glob(round_A_box_folder + \"*.xml\")\n",
    "box_file_name_list = [x.split('\\\\')[1] for x in box_file_path_list]\n",
    "\n",
    "image_file_name_list = [(x.split('.')[0] + '.jpg') for x in box_file_name_list]\n",
    "image_file_path_list = [(round_A_image_folder + x) for x in image_file_name_list]\n",
    "\n",
    "\n",
    "def read_image(image_file_path_list):\n",
    "    image_array_list = []\n",
    "    for image_file_path in image_file_path_list:\n",
    "        image = Image.open(image_file_path)\n",
    "        image_data = image.getdata()\n",
    "        image_array = np.array(image_data)\n",
    "        image_array_list.append(image_array)\n",
    "    return image_array_list\n",
    "#best IOU anchor\n",
    "def cross_length(a_1, a_2, b_1, b_2):\n",
    "    if a_1 <=b_1 and a_2 >= b_1:\n",
    "        return (min(a_2, b_2) - b_1)\n",
    "    elif a_1 <=b_1 and a_2 <= b_1:\n",
    "        return 0\n",
    "    else:\n",
    "        return cross_length(b_1, b_2, a_1, a_2)\n",
    "\"\"\"\n",
    "def IoU(x_GT, y_GT, w_GT, h_GT, x_PD, y_PD, w_PD, h_PD):\n",
    "    area_of_I = cross_length(x_GT, x_GT + w_GT, x_PD, x_PD + w_PD) * cross_length(y_GT, y_GT + h_GT, y_PD, y_PD + h_PD)\n",
    "    area_of_U = h_GT * w_GT + h_PD * w_PD - area_of_I\n",
    "    return area_of_I / area_of_U\n",
    "\"\"\"\n",
    "anchors = [12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401]\n",
    "anchor_shape_1 = int(len(anchors) / 2)\n",
    "anchors = np.array(anchors).reshape(anchor_shape_1, 2)\n",
    "def best_anchor(image_info):\n",
    "    max_IoU = 0\n",
    "    for m in range(9):\n",
    "        x_GT = 0\n",
    "        y_GT = 0\n",
    "        w_GT = image_info[9]\n",
    "        h_GT = image_info[10]\n",
    "        x_PD = image_info[9] / 2 - anchors[m][0] / 2\n",
    "        y_PD = image_info[10] / 2 - anchors[m][1] / 2\n",
    "        w_PD = anchors[m][0]\n",
    "        h_PD = anchors[m][1]\n",
    "        \n",
    "        current_IOU = IoU(x_GT, y_GT, w_GT, h_GT, x_PD, y_PD, w_PD, h_PD)\n",
    "        #print(current_IOU)\n",
    "        if current_IOU >= max_IoU:\n",
    "            max_IoU = current_IOU\n",
    "            selected_anchors = m\n",
    "    \n",
    "    if selected_anchors < 3:\n",
    "        grid_size = 608 / 76\n",
    "    elif selected_anchors < 6:\n",
    "        grid_size = 608 / 38\n",
    "    elif selected_anchors < 9:\n",
    "        grid_size = 608 / 19\n",
    "    \n",
    "    grid_no_x = int((image_info[2] + image_info[4]) / 2 / grid_size)\n",
    "    grid_no_y = int((image_info[3] + image_info[5]) / 2 / grid_size)\n",
    "    \n",
    "    w_expanded_time = image_info[9] / w_PD\n",
    "    h_expanded_time = image_info[10] / h_PD\n",
    "    \n",
    "    position_x = (image_info[2] + image_info[4]) / 2 / grid_size - grid_no_x\n",
    "    position_y = (image_info[3] + image_info[5]) / 2 / grid_size - grid_no_y\n",
    "    \n",
    "    #print(image_info)\n",
    "    #print(grid_no_x)\n",
    "    #print(grid_no_y)\n",
    "    return selected_anchors, grid_no_x, grid_no_y, position_x, position_y, w_expanded_time, h_expanded_time\n",
    "\n",
    "def read_xml_into_training_data(box_file_path_list):\n",
    "    All_image = []\n",
    "    for box_file_path in box_file_path_list:\n",
    "        dict_object = {\"holothurian\": 0, \"echinus\": 1, \"scallop\": 2, \"starfish\": 3}\n",
    "        tree = ET.parse(box_file_path)\n",
    "        root = tree.getroot()\n",
    "        \"\"\"\n",
    "        root.tag\n",
    "        root.attrib\n",
    "        \n",
    "        for child in root:\n",
    "            for sub_child in child:\n",
    "                print(sub_child.tag)\n",
    "        \"\"\"\n",
    "        \n",
    "        object = [None for i in range(6)]\n",
    "        All_object = []\n",
    "        All_image_size = []\n",
    "        image_size = [None, None]\n",
    "        frame_name = []\n",
    "        image_size_width = []\n",
    "        image_size_height = []\n",
    "        object_name = []\n",
    "        object_type = []\n",
    "        object_xmin = []\n",
    "        object_ymin = []\n",
    "        object_xmax = []\n",
    "        object_ymax = []\n",
    "\n",
    "        for name in root.findall(\"./frame\"):\n",
    "            frame_name.append(name.text)\n",
    "        for name in root.findall(\"./size/width\"):\n",
    "            image_size_width.append(int(name.text))\n",
    "        for name in root.findall(\"./size/height\"):\n",
    "            image_size_height.append(int(name.text))\n",
    "\n",
    "        for name in root.findall(\"./object/name\"):\n",
    "            object_name.append(name.text)\n",
    "\n",
    "        for name in root.findall(\"./object/bndbox/xmin\"):\n",
    "            object_xmin.append(int(name.text))\n",
    "        for name in root.findall(\"./object/bndbox/ymin\"):\n",
    "            object_ymin.append(int(name.text))\n",
    "        for name in root.findall(\"./object/bndbox/xmax\"):\n",
    "            object_xmax.append(int(name.text))\n",
    "        for name in root.findall(\"./object/bndbox/ymax\"):\n",
    "            object_ymax.append(int(name.text))\n",
    "\n",
    "        for i in range(len(object_name)):\n",
    "            current_object = []\n",
    "            current_object.append(object_name[i])\n",
    "            current_object.append(dict_object[object_name[i]])\n",
    "            current_object.append(object_xmin[i])\n",
    "            current_object.append(object_ymin[i])\n",
    "            current_object.append(object_xmax[i])\n",
    "            current_object.append(object_ymax[i])\n",
    "            current_object.append(frame_name[0])\n",
    "            current_object.append(image_size_width[0])\n",
    "            current_object.append(image_size_height[0])\n",
    "            All_object.append(current_object)\n",
    "        All_image.append(All_object)\n",
    "    return All_image\n",
    "\n",
    "\n",
    "training_input_data = read_image(image_file_path_list[0: 2])\n",
    "\n",
    "All_image = read_xml_into_training_data(box_file_path_list[0:200])\n",
    "\n",
    "yolo_size = 608\n",
    "\n",
    "for i in range(len(All_image)):\n",
    "    for j in range(len(All_image[i])):\n",
    "        All_image[i][j][2] = All_image[i][j][2] / All_image[i][j][7] * yolo_size\n",
    "        All_image[i][j][4] = All_image[i][j][4] / All_image[i][j][7] * yolo_size\n",
    "        All_image[i][j][3] = All_image[i][j][3] / All_image[i][j][8] * yolo_size\n",
    "        All_image[i][j][5] = All_image[i][j][5] / All_image[i][j][8] * yolo_size\n",
    "        All_image[i][j].append(All_image[i][j][4] - All_image[i][j][2])\n",
    "        All_image[i][j].append(All_image[i][j][5] - All_image[i][j][3])\n",
    "        selected_anchors, grid_no_x, grid_no_y, position_x, position_y, w_expanded_time, h_expanded_time = best_anchor(All_image[i][j])\n",
    "        All_image[i][j].append(selected_anchors)\n",
    "        All_image[i][j].append(grid_no_x)\n",
    "        All_image[i][j].append(grid_no_y)\n",
    "        All_image[i][j].append(position_x)\n",
    "        All_image[i][j].append(position_y)\n",
    "        All_image[i][j].append(w_expanded_time)\n",
    "        All_image[i][j].append(h_expanded_time)\n",
    "        \n",
    "All_image[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.3/2 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 1): 6.1981144\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 2): 6.1947365\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 3): 6.19388\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 4): 6.1933913\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 5): 6.193056\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 6): 6.192813\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 7): 6.1926203\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 8): 6.192468\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 9): 6.1923404\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 10): 6.192233\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 11): 6.192168\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 12): 6.192115\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 13): 6.192066\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 14): 6.192027\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 15): 6.191989\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 16): 6.1919527\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 17): 6.1919184\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 18): 6.191887\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 19): 6.191857\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 20): 6.1918273\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 21): 6.191798\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 22): 6.1917686\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 23): 6.1917424\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 24): 6.191722\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 25): 6.191701\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 26): 6.1916814\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 27): 6.1916614\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 28): 6.191642\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 29): 6.1916223\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 30): 6.191611\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 31): 6.191605\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 32): 6.191601\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 33): 6.191595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 34): 6.1915894\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 35): 6.1915846\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 36): 6.19158\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 37): 6.1915765\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 38): 6.1915727\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 39): 6.1915684\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 40): 6.1915646\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 41): 6.1915607\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 42): 6.191557\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 43): 6.191553\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 44): 6.1915493\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 45): 6.1915464\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 46): 6.191544\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 47): 6.1915426\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 48): 6.1915402\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 49): 6.191538\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 50): 6.1915355\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 51): 6.191534\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 52): 6.191532\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 53): 6.1915298\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 54): 6.1915274\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 55): 6.1915255\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 56): 6.1915236\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 57): 6.191522\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 58): 6.1915197\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 59): 6.1915183\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 60): 6.1915164\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 61): 6.191514\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 62): 6.191513\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 63): 6.191512\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 64): 6.191511\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 65): 6.19151\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 66): 6.1915097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 67): 6.1915097\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 68): 6.191509\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 69): 6.1915083\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 70): 6.1915083\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 71): 6.1915073\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 72): 6.191507\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 73): 6.1915064\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 74): 6.191506\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 75): 6.191505\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 76): 6.1915054\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 77): 6.1915045\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 78): 6.1915035\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 79): 6.1915035\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 80): 6.1915026\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 81): 6.191502\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 82): 6.191502\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 83): 6.191501\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 84): 6.1915007\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 85): 6.1914997\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 86): 6.1914997\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 87): 6.1914988\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 88): 6.1914988\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 89): 6.1914983\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 90): 6.191498\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 91): 6.1914973\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 92): 6.191497\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 93): 6.191496\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 94): 6.191496\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 95): 6.191495\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 96): 6.191495\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 97): 6.1914945\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 98): 6.1914935\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 99): 6.191493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(2.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Loss (epoch: 100): 6.191493\n"
     ]
    }
   ],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)\n",
    "#training loop for transfer layer\n",
    "def TL_model_training():\n",
    "    learning_rate = 0.002\n",
    "    epoch_size = 100\n",
    "    batch_size = 1\n",
    "    steps_for_printing_out_loss = 1\n",
    "    \n",
    "    loss_function_MSE = nn.MSELoss(size_average=False)\n",
    "    loss_function_BCE = nn.BCELoss(size_average=False)\n",
    "    \n",
    "    #loss_function_MSE = nn.MSELoss()\n",
    "    #loss_function_BCE = nn.BCELoss()\n",
    "    \n",
    "    TL_model = transfer_learning_model().cuda()\n",
    "    \n",
    "    #TL_model.load_state_dict(torch.load('Model/TL_model_starting_point.pt')['state_dict'])\n",
    "    optimizer = optim.SGD(TL_model.parameters(), lr = learning_rate)\n",
    "    TL_model.eval()\n",
    "    \n",
    "    for i in range(1, epoch_size + 1):\n",
    "        #loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        total_loss = 0\n",
    "        for image_pt_name in range(0, 1):\n",
    "            \n",
    "            file_name = 'F:/FlyAI/TL_input_data/' + str(image_pt_name) + '.pt'\n",
    "            input_data = torch.load(file_name)\n",
    "            layer_137_out = input_data['output_137'].cuda()\n",
    "            layer_148_out = input_data['output_148'].cuda()\n",
    "            layer_159_out = input_data['output_159'].cuda()\n",
    "            #print(layer_137_out.shape)\n",
    "\n",
    "            \n",
    "            \n",
    "            output_76, output_38, output_19 = TL_model(layer_137_out, layer_148_out, layer_159_out)\n",
    "            output_file_name = 'F:/FlyAI/TL_output_data/' + str(image_pt_name) + '.pt'\n",
    "            torch.save({'output_76': output_76, 'output_38': output_38, 'output_19': output_19}, output_file_name)\n",
    "            \n",
    "            target_76 = output_76.clone()\n",
    "            target_38 = output_38.clone()\n",
    "            target_19 = output_19.clone()\n",
    "            #there is a possibility of more than one GT are mapped into same grid of a anchor, may need to check from training data?\n",
    "            image_set = range(0, 1)\n",
    "            target_76[:,:,4,:,:] = 0\n",
    "            target_38[:,:,4,:,:] = 0\n",
    "            target_19[:,:,4,:,:] = 0\n",
    "            \n",
    "            for image_no in image_set:\n",
    "                image_no_current_batch = image_no % batch_size\n",
    "                \n",
    "                for item in All_image[image_pt_name]:\n",
    "                    #print(item)\n",
    "                    anchor_no = item[11] % 3\n",
    "                    grid_x = item[12]\n",
    "                    grid_y = item[13]\n",
    "\n",
    "                    obj_class_no = item[1]\n",
    "                    central_x = (item[2] + item[4]) / 2\n",
    "                    central_y = (item[3] + item[5]) / 2\n",
    "                    width_x = item[9]\n",
    "                    height_y = item[10]\n",
    "                    \n",
    "                    position_x = item[14]\n",
    "                    position_y = item[15]\n",
    "                    w_expanded_time = item[16]\n",
    "                    h_expanded_time = item[17]\n",
    "                    \n",
    "                    if item[11] < 3:\n",
    "                        #target_76[anchor_no,image_no_current_batch,4,:,:] = 0\n",
    "                        target_76[anchor_no,image_no_current_batch,0,grid_y,grid_x] = position_x\n",
    "                        target_76[anchor_no,image_no_current_batch,1,grid_y,grid_x] = position_y\n",
    "                        target_76[anchor_no,image_no_current_batch,2,grid_y,grid_x] = w_expanded_time\n",
    "                        target_76[anchor_no,image_no_current_batch,3,grid_y,grid_x] = h_expanded_time\n",
    "                        target_76[anchor_no,image_no_current_batch,4,grid_y,grid_x] = 1\n",
    "\n",
    "                        target_76[anchor_no,image_no_current_batch,5:9,grid_y,grid_x] = 0\n",
    "                        target_76[anchor_no,image_no_current_batch,5 + obj_class_no,grid_y,grid_x] = 1\n",
    "                    elif item[11] < 6:\n",
    "                        #target_38[anchor_no,image_no_current_batch,4,:,:] = 0\n",
    "                        target_38[anchor_no,image_no_current_batch,0,grid_y,grid_x] = position_x\n",
    "                        target_38[anchor_no,image_no_current_batch,1,grid_y,grid_x] = position_y\n",
    "                        target_38[anchor_no,image_no_current_batch,2,grid_y,grid_x] = w_expanded_time\n",
    "                        target_38[anchor_no,image_no_current_batch,3,grid_y,grid_x] = h_expanded_time\n",
    "                        target_38[anchor_no,image_no_current_batch,4,grid_y,grid_x] = 1\n",
    "\n",
    "                        target_38[anchor_no,image_no_current_batch,5:9,grid_y,grid_x] = 0\n",
    "                        target_38[anchor_no,image_no_current_batch,5 + obj_class_no,grid_y,grid_x] = 1\n",
    "                    elif item[11] < 9:\n",
    "                        #target_19[anchor_no,image_no_current_batch,4,:,:] = 0\n",
    "                        target_19[anchor_no,image_no_current_batch,0,grid_y,grid_x] = position_x\n",
    "                        target_19[anchor_no,image_no_current_batch,1,grid_y,grid_x] = position_y\n",
    "                        target_19[anchor_no,image_no_current_batch,2,grid_y,grid_x] = w_expanded_time\n",
    "                        target_19[anchor_no,image_no_current_batch,3,grid_y,grid_x] = h_expanded_time\n",
    "                        target_19[anchor_no,image_no_current_batch,4,grid_y,grid_x] = 1\n",
    "\n",
    "                        target_19[anchor_no,image_no_current_batch,5:9,grid_y,grid_x] = 0\n",
    "                        target_19[anchor_no,image_no_current_batch,5 + obj_class_no,grid_y,grid_x] = 1\n",
    "\n",
    "            #global output_tensor\n",
    "            #output_tensor = output\n",
    "            #print(output_76.shape)\n",
    "            #print(output_76)\n",
    "            \n",
    "            target_file_name = 'F:/FlyAI/TL_output_data/target_' + str(image_pt_name) + '.pt'\n",
    "            torch.save({'target_76': target_76, 'target_38': target_38, 'target_19': target_19}, target_file_name)\n",
    "            \n",
    "            \n",
    "            \n",
    "            target_76 = Variable(target_76, requires_grad=False)\n",
    "            target_38 = Variable(target_38, requires_grad=False)\n",
    "            target_19 = Variable(target_19, requires_grad=False)\n",
    "            \n",
    "            #print(target_76[0])\n",
    "\n",
    "            loss_w_h = loss_function_MSE(output_76[:, :, 2 : 4, :, :], target_76[:, :, 2 : 4, :, :])\\\n",
    "             + loss_function_MSE(output_38[:, :, 2 : 4, :, :], target_38[:, :, 2 : 4, :, :])\\\n",
    "             + loss_function_MSE(output_19[:, :, 2 : 4, :, :], target_19[:, :, 2 : 4, :, :])\n",
    "            \n",
    "            loss_w_h = loss_w_h / 2\n",
    "            \n",
    "            loss_class = loss_function_BCE(output_76[:, :, 5 : 9, :, :], target_76[:, :, 5 : 9, :, :])\\\n",
    "             + loss_function_BCE(output_38[:, :, 5 : 9, :, :], target_38[:, :, 5 : 9, :, :])\\\n",
    "             + loss_function_BCE(output_19[:, :, 5 : 9, :, :], target_19[:, :, 5 : 9, :, :])\n",
    "            \n",
    "            loss_obj_p = loss_function_BCE(output_76[:, :, 4, :, :], target_76[:, :, 4, :, :])\\\n",
    "             + loss_function_BCE(output_38[:, :, 4, :, :], target_38[:, :, 4, :, :])\\\n",
    "             + loss_function_BCE(output_19[:, :, 4, :, :], target_19[:, :, 4, :, :])\n",
    "            \n",
    "            loss_x_y = loss_function_BCE(output_76[:, :, 0 : 2, :, :], target_76[:, :, 0 : 2, :, :])\\\n",
    "             + loss_function_BCE(output_38[:, :, 0 : 2, :, :], target_38[:, :, 0 : 2, :, :])\\\n",
    "             + loss_function_BCE(output_19[:, :, 0 : 2, :, :], target_19[:, :, 0 : 2, :, :])\n",
    "            \n",
    "            loss = loss_w_h + loss_class + loss_obj_p + loss_x_y\n",
    "            #loss = loss_function_MSE(output_76, target_76) + loss_function_MSE(output_38, target_38) + loss_function_MSE(output_19, target_19)\n",
    "            print(loss_w_h)\n",
    "            print(loss_class)\n",
    "            print(loss_obj_p)\n",
    "            print(loss_x_y)\n",
    "            total_loss += loss\n",
    "            loss.backward()\n",
    "            \n",
    "        #loss = loss_function(output_76, target_76)\n",
    "        \n",
    "        optimizer.step()\n",
    "        if i % (steps_for_printing_out_loss) == 0:\n",
    "            print('Loss (epoch: ' + str(i) + '): ' + str(total_loss.cpu().detach().numpy()))\n",
    "    torch.save({'state_dict': TL_model.state_dict(),'optimizer': optimizer.state_dict()}, TL_model_file_path)\n",
    "\n",
    "TL_model_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pt_name = 0\n",
    "target_file_name = 'F:/FlyAI/TL_output_data/' + str(image_pt_name) + '.pt'\n",
    "\n",
    "target_data = torch.load(target_file_name)\n",
    "target_76 = target_data['output_76']\n",
    "target_38 = target_data['output_38']\n",
    "target_19 = target_data['output_19']\n",
    "print(target_38[:,:,5,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pt_name = 0\n",
    "output_file_name = 'F:/FlyAI/TL_output_data/' + str(image_pt_name) + '.pt'\n",
    "\n",
    "output_data = torch.load(output_file_name)\n",
    "output_76 = output_data['output_76']\n",
    "output_38 = output_data['output_38']\n",
    "output_19 = output_data['output_19']\n",
    "print(output_38[:,:,5,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pt_name = 0\n",
    "target_file_name = 'F:/FlyAI/TL_output_data/target_' + str(image_pt_name) + '.pt'\n",
    "\n",
    "target_data = torch.load(target_file_name)\n",
    "target_76 = target_data['target_76'].cuda()\n",
    "target_38 = target_data['target_38'].cuda()\n",
    "target_19 = target_data['target_19'].cuda()\n",
    "\n",
    "target_76 = torch.transpose(target_76, 2, 4)\n",
    "target_38 = torch.transpose(target_38, 2, 4)\n",
    "target_19 = torch.transpose(target_19, 2, 4)\n",
    "\n",
    "target_76 = target_76.reshape(3 * 76**2, 9)\n",
    "target_38 = target_38.reshape(3 * 38**2, 9)\n",
    "target_19 = target_19.reshape(3 * 19**2, 9)\n",
    "\n",
    "from numpy import savetxt\n",
    "savetxt('data_t.csv', target_76.cpu().detach().numpy(), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22743, 9])\n"
     ]
    }
   ],
   "source": [
    "image_pt_name = 0\n",
    "output_file_name = 'F:/FlyAI/TL_output_data/' + str(image_pt_name) + '.pt'\n",
    "\n",
    "output_data = torch.load(output_file_name)\n",
    "output_76 = output_data['output_76'].cuda()\n",
    "output_38 = output_data['output_38'].cuda()\n",
    "output_19 = output_data['output_19'].cuda()\n",
    "\n",
    "output_76 = torch.transpose(output_76, 2, 4)\n",
    "output_38 = torch.transpose(output_38, 2, 4)\n",
    "output_19 = torch.transpose(output_19, 2, 4)\n",
    "\n",
    "output_76 = output_76.reshape(3 * 76**2, 9)\n",
    "output_38 = output_38.reshape(3 * 38**2, 9)\n",
    "output_19 = output_19.reshape(3 * 19**2, 9)\n",
    "\n",
    "from numpy import savetxt\n",
    "savetxt('data.csv', output_76.cpu().detach().numpy(), delimiter=',')\n",
    "#output_76 = torch.cat((output_76[0], output_76[1], output_76[2]), 0)\n",
    "#output_38 = torch.cat((output_38[0], output_38[1], output_38[2]), 0)\n",
    "#output_19 = torch.cat((output_19[0], output_19[1], output_19[2]), 0)\n",
    "\n",
    "\n",
    "sum(x**2 for x in (19, 38, 76))\n",
    "\n",
    "output = torch.cat((output_76, output_38, output_19), 0)\n",
    "print(output.shape)\n",
    "obj_threshold = 0.53\n",
    "updated_outcome = []\n",
    "for item in output:\n",
    "    if item[4] >= obj_threshold:\n",
    "        updated_outcome.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(updated_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(x_GT, y_GT, w_GT, h_GT, x_PD, y_PD, w_PD, h_PD):\n",
    "    area_of_I = cross_length(x_GT, x_GT + w_GT, x_PD, x_PD + w_PD) * cross_length(y_GT, y_GT + h_GT, y_PD, y_PD + h_PD)\n",
    "    area_of_U = h_GT * w_GT + h_PD * w_PD - area_of_I\n",
    "    return area_of_I / area_of_U\n",
    "\n",
    "#len(updated_outcome)\n",
    "#updated_outcome = updated_outcome[0:9]\n",
    "#print(updated_outcome.shape)\n",
    "def sort_column(elem):\n",
    "    return elem[4]\n",
    "updated_outcome.sort(key = sort_column, reverse=True)\n",
    "\n",
    "#updated_outcome = updated_outcome[updated_outcome[:,0].argsort()]\n",
    "\n",
    "#print(updated_outcome)\n",
    "\n",
    "\n",
    "#sort by obj possibility\n",
    "IoU_threshold = 0.5\n",
    "final_list = []\n",
    "#print(updated_outcome)\n",
    "#updated_outcome[0][3] = 6\n",
    "\n",
    "for origin_item in updated_outcome:\n",
    "    #print(final_list)\n",
    "    if final_list == []:\n",
    "        final_list.append(origin_item)\n",
    "        continue\n",
    "    indicator = 1\n",
    "    for new_item in final_list:\n",
    "        #print(IoU(new_item[0] - new_item[2]/2, new_item[1] - new_item[3]/2, new_item[2], new_item[3], origin_item[0] - origin_item[2]/2, origin_item[1] - origin_item[3]/2, origin_item[2], origin_item[3]))\n",
    "        if IoU(new_item[0] - new_item[2]/2, new_item[1] - new_item[3]/2, new_item[2], new_item[3], origin_item[0] - origin_item[2]/2, origin_item[1] - origin_item[3]/2, origin_item[2], origin_item[3]) < IoU_threshold:\n",
    "            indicator *= 1\n",
    "        else:\n",
    "            indicator *= 0\n",
    "            break\n",
    "    if indicator == 1:\n",
    "        final_list.append(origin_item)\n",
    "\n",
    "final_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function - Done\n",
    "\n",
    "\"\"\"\n",
    "- objective possibility: except GT grids are 1, all others are 0\n",
    "- class: 0, 1 only for GT grids, rest should be ignore (equal to predicted result)\n",
    "- x, y, w, h only for GT grids, rest should be ignore (equal to predicted result)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#grab yolov4 weight into TL - Done\n",
    "#convert training data into 60GB mid input data\n",
    "##########NMS (possibility threshold, IOU threshold, max 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 1 layer's parameter\n",
    "\n",
    "\n",
    "\n",
    "#convert result into FlyAI format\n",
    "#change back to normal pic size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_details[160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_layers\n",
    "n = [76, 38, 19]\n",
    "m = [608 / i for i in n for m in range(6)] \n",
    "print(m)\n",
    "\n",
    "\n",
    "anchor = [12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401]\n",
    "[anchor[i] / m[i] for i in range(len(m))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_v4_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.YOLO_v4_layers = nn.ModuleList()\n",
    "        \n",
    "            self.YOLO_v4_layers.append(Conv_Layer_box(in_channel[i], out_channel[i], kernel_size= kernel_size[i], stride = stride[i], activation_func = activation_func[i], batch_normalization = batch_normalization[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class abc():\n",
    "    def __init__(self, qwe, out):\n",
    "        print(qwe)\n",
    "        \n",
    "abc(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = \"1,2,3\"\n",
    "m = abc.split(\",\")\n",
    "m\n",
    "abc = \"1\"\n",
    "m = abc.split(\",\")\n",
    "m\n",
    "k = 4\n",
    "\n",
    "HX = []\n",
    "\n",
    "for r in k:\n",
    "    print(r)\n",
    "    print(k[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightfile = \"D:/Installation/yolov4.weights\"\n",
    "fp = open(weightfile, 'rb')\n",
    "header = np.fromfile(fp, count=5, dtype=np.int32)\n",
    "header = torch.from_numpy(header)\n",
    "seen = header[3]\n",
    "buf = np.fromfile(fp, dtype=np.float32)\n",
    "fp.close()\n",
    "\n",
    "start = 0\n",
    "ind = -2\n",
    "buf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HX_weight = YOLO_v4_Module_WIP.state_dict()\n",
    "i = 0\n",
    "HX = []\n",
    "\n",
    "for kk in HX_weight:\n",
    "    i += 1\n",
    "    print(kk)\n",
    "    print(HX_weight[kk].size())\n",
    "    HX.append(HX_weight[kk].size())\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.load(\"D:/Installation/yolov4.pt\")\n",
    "#d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = d['model']\n",
    "weight_bank = []\n",
    "i = 0\n",
    "yolo_v4_size = []\n",
    "for kk in mm:\n",
    "    i += 1\n",
    "    print(kk)\n",
    "    print(mm[kk].size())\n",
    "    weight_bank.append(mm[kk])\n",
    "    yolo_v4_size.append(mm[kk].size())\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weight_bank)\n",
    "#update weight into model\n",
    "\n",
    "i = 0\n",
    "HX = []\n",
    "\n",
    "for kk in YOLO_v4_Module_WIP.state_dict():\n",
    "    print(kk)\n",
    "    YOLO_v4_Module_WIP.state_dict()[kk] = weight_bank[i]\n",
    "    i += 1\n",
    "    #HX.append(HX_weight[kk].size())\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(yolo_v4_size)):\n",
    "    #print(yolo_v4_size[i] == HX[i])\n",
    "    if (yolo_v4_size[i] == HX[i]) == False:\n",
    "        print(yolo_v4_size[i])\n",
    "        print(HX[i])\n",
    "        print(i)\n",
    "    print(yolo_v4_size[i] == HX[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOLO_v4_Module_WIP.state_dict()\n",
    "torch.save({'state_dict': YOLO_v4_Module_WIP.state_dict(),'optimizer': optimizer.state_dict()}, model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TL parameter:\n",
    "d = torch.load(\"D:/Installation/yolov4.pt\")\n",
    "mm = d['model']\n",
    "weight_bank = []\n",
    "i = 0\n",
    "yolo_v4_size = []\n",
    "for kk in mm:\n",
    "    i += 1\n",
    "    print(kk)\n",
    "    print(mm[kk].size())\n",
    "    weight_bank.append(mm[kk])\n",
    "    yolo_v4_size.append(mm[kk].size())\n",
    "print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TL parameter:\n",
    "d = torch.load(TL_model_file_path)\n",
    "mm = d['state_dict']\n",
    "weight_bank = []\n",
    "i = 0\n",
    "yolo_v4_size = []\n",
    "for kk in mm:\n",
    "    i += 1\n",
    "    print(kk)\n",
    "    print(mm[kk].size())\n",
    "    weight_bank.append(mm[kk])\n",
    "    yolo_v4_size.append(mm[kk].size())\n",
    "print(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(weight_bank)\n",
    "#update weight into model\n",
    "TL_model_weight = torch.load(TL_model_file_path)\n",
    "YOLO_v4_weight = torch.load(\"D:/Installation/yolov4.pt\")['model']\n",
    "i = 0\n",
    "HX = []\n",
    "\n",
    "TL_model_weight['state_dict']['Conv_Layer_76_a.conv_box.0.weight'] = YOLO_v4_weight['module_list.138.Conv2d.weight']\n",
    "TL_model_weight['state_dict']['Conv_Layer_76_a.conv_box.0.bias'] = YOLO_v4_weight['module_list.138.Conv2d.bias']\n",
    "TL_model_weight['state_dict']['Conv_Layer_38_a.conv_box.0.weight'] = YOLO_v4_weight['module_list.149.Conv2d.weight']\n",
    "TL_model_weight['state_dict']['Conv_Layer_38_a.conv_box.0.bias'] = YOLO_v4_weight['module_list.149.Conv2d.bias']\n",
    "TL_model_weight['state_dict']['Conv_Layer_19_a.conv_box.0.weight'] = YOLO_v4_weight['module_list.160.Conv2d.weight']\n",
    "TL_model_weight['state_dict']['Conv_Layer_19_a.conv_box.0.bias'] = YOLO_v4_weight['module_list.160.Conv2d.bias']\n",
    "torch.save(TL_model_weight, 'Model/TL_model_starting_point.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = TL_model_weight['state_dict']\n",
    "weight_bank = []\n",
    "i = 0\n",
    "yolo_v4_size = []\n",
    "for kk in mm:\n",
    "    i += 1\n",
    "    print(kk)\n",
    "    print(mm[kk].size())\n",
    "    weight_bank.append(mm[kk])\n",
    "    yolo_v4_size.append(mm[kk].size())\n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    if i == 2:\n",
    "        continue\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
