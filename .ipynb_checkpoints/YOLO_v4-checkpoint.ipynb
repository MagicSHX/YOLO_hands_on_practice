{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mnist import MNIST\n",
    "import torch\n",
    "from torch import nn\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * torch.tanh(F.softplus(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_Layer_box(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride, activation_func, batch_normalization):\n",
    "        super().__init__()\n",
    "        padding = (int((kernel_size - 1)/2), int((kernel_size - 1)/2))\n",
    "        \n",
    "        dict_activation_func = {\"ReLU\": nn.ReLU(inplace=True),\n",
    "                                \"LeakyReLU\": nn.LeakyReLU(0.1, inplace=True),\n",
    "                                \"Mish\": Mish()\n",
    "                               }\n",
    "        \n",
    "        if batch_normalization == True:\n",
    "            bias = False\n",
    "        else:\n",
    "            bias = True\n",
    "        self.conv_box = nn.ModuleList()\n",
    "        self.conv_box.append(nn.Conv2d(in_channel, out_channel, kernel_size = kernel_size, stride = stride, padding = padding, bias = bias))\n",
    "        if batch_normalization == True:\n",
    "            self.conv_box.append(nn.BatchNorm2d(out_channel))\n",
    "        self.conv_box.append(dict_activation_func[activation_func])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.conv_box:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_v4_1st_RSL_Layer_group(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer_0 = Conv_Layer_box(3, 32, kernel_size=3, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.conv_layer_1 = Conv_Layer_box(32, 64, kernel_size=3, stride = 2, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.conv_layer_2 = Conv_Layer_box(64, 64, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "\n",
    "        #route - name - 3\n",
    "        self.conv_layer_4 = Conv_Layer_box(64, 64, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.conv_layer_5 = Conv_Layer_box(64, 32, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        self.conv_layer_6 = Conv_Layer_box(32, 64, kernel_size=3, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        #shortcut?????? - name - 7\n",
    "        self.conv_layer_8 = Conv_Layer_box(64, 64, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "        #route - name - 9\n",
    "        self.conv_layer_9 = Conv_Layer_box(64, 128, kernel_size=1, stride = 1, activation_func = \"Mish\", batch_normalization = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_0 = self.conv_layer_0(x)\n",
    "        out_1 = self.conv_layer_1(out_0)\n",
    "        out_4 = self.conv_layer_4(out_1)\n",
    "        out_5 = self.conv_layer_5(out_4)\n",
    "        out_6 = self.conv_layer_6(out_5)\n",
    "        shortcut_7 = out_6 + out_1\n",
    "        out_8 = self.conv_layer_8(shortcut_7)\n",
    "        out_2 = self.conv_layer_2(out_1)\n",
    "        route_9 = out_8 + out_2\n",
    "        out_9 = self.conv_layer_9(route_9)\n",
    "        out = out_9\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_v4_2nd_RSL_Layer_group(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer_1 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=(1,1))\n",
    "        \n",
    "        self.RSL_conv_1 = nn.Conv2d(128, 64, kernel_size=1)\n",
    "        self.RSL_conv_2 = nn.Conv2d(64, 128, kernel_size=3, padding=(1,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_layer_1(x)\n",
    "        \n",
    "        x2 = RSL_conv_1(x1)\n",
    "        x3 = RSL_conv_2(x2)\n",
    "        x4 = x1 + x3\n",
    "        \n",
    "        x5 = RSL_conv_1(x4)\n",
    "        x6 = RSL_conv_2(x5)\n",
    "        x7 = x4 + x6\n",
    "        \n",
    "        out = x7 + x1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_v4_3rd_RSL_Layer_group(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer_1 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=(1,1))\n",
    "        \n",
    "        self.RSL_conv_1 = nn.Conv2d(256, 128, kernel_size=1)\n",
    "        self.RSL_conv_2 = nn.Conv2d(128, 256, kernel_size=3, padding=(1,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_layer_1(x)\n",
    "        \n",
    "        x2 = RSL_conv_1(x1)\n",
    "        x3 = RSL_conv_2(x2)\n",
    "        x4 = x1 + x3\n",
    "        \n",
    "        x5 = RSL_conv_1(x4)\n",
    "        x6 = RSL_conv_2(x5)\n",
    "        x7 = x4 + x6\n",
    "        \n",
    "        x8 = RSL_conv_1(x7)\n",
    "        x9 = RSL_conv_2(x8)\n",
    "        x10 = x7 + x9\n",
    "        \n",
    "        x11 = RSL_conv_1(x10)\n",
    "        x12 = RSL_conv_2(x11)\n",
    "        x13 = x10 + x12\n",
    "        \n",
    "        x14 = RSL_conv_1(x13)\n",
    "        x15 = RSL_conv_2(x14)\n",
    "        x16 = x13 + x15\n",
    "        \n",
    "        x17 = RSL_conv_1(x16)\n",
    "        x18 = RSL_conv_2(x17)\n",
    "        x19 = x16 + x18\n",
    "        \n",
    "        x20 = RSL_conv_1(x19)\n",
    "        x21 = RSL_conv_2(x20)\n",
    "        x22 = x19 + x21\n",
    "        \n",
    "        x23 = RSL_conv_1(x22)\n",
    "        x24 = RSL_conv_2(x23)\n",
    "        x25 = x22 + x24\n",
    "        \n",
    "        out = x25 + x1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_v4_4th_RSL_Layer_group(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer_1 = nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=(1,1))\n",
    "        \n",
    "        self.RSL_conv_1 = nn.Conv2d(512, 256, kernel_size=1)\n",
    "        self.RSL_conv_2 = nn.Conv2d(256, 512, kernel_size=3, padding=(1,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_layer_1(x)\n",
    "        \n",
    "        x2 = RSL_conv_1(x1)\n",
    "        x3 = RSL_conv_2(x2)\n",
    "        x4 = x1 + x3\n",
    "        \n",
    "        x5 = RSL_conv_1(x4)\n",
    "        x6 = RSL_conv_2(x5)\n",
    "        x7 = x4 + x6\n",
    "        \n",
    "        x8 = RSL_conv_1(x7)\n",
    "        x9 = RSL_conv_2(x8)\n",
    "        x10 = x7 + x9\n",
    "        \n",
    "        x11 = RSL_conv_1(x10)\n",
    "        x12 = RSL_conv_2(x11)\n",
    "        x13 = x10 + x12\n",
    "        \n",
    "        x14 = RSL_conv_1(x13)\n",
    "        x15 = RSL_conv_2(x14)\n",
    "        x16 = x13 + x15\n",
    "        \n",
    "        x17 = RSL_conv_1(x16)\n",
    "        x18 = RSL_conv_2(x17)\n",
    "        x19 = x16 + x18\n",
    "        \n",
    "        x20 = RSL_conv_1(x19)\n",
    "        x21 = RSL_conv_2(x20)\n",
    "        x22 = x19 + x21\n",
    "        \n",
    "        x23 = RSL_conv_1(x22)\n",
    "        x24 = RSL_conv_2(x23)\n",
    "        x25 = x22 + x24\n",
    "        \n",
    "        out = x25 + x1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_v4_5th_RSL_Layer_group(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer_1 = nn.Conv2d(512, 1024, kernel_size=3, stride=2, padding=(1,1))\n",
    "        \n",
    "        self.RSL_conv_1 = nn.Conv2d(1024, 512, kernel_size=1)\n",
    "        self.RSL_conv_2 = nn.Conv2d(512, 1024, kernel_size=3, padding=(1,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_layer_1(x)\n",
    "        \n",
    "        x2 = RSL_conv_1(x1)\n",
    "        x3 = RSL_conv_2(x2)\n",
    "        x4 = x1 + x3\n",
    "        \n",
    "        x5 = RSL_conv_1(x4)\n",
    "        x6 = RSL_conv_2(x5)\n",
    "        x7 = x4 + x6\n",
    "        \n",
    "        x8 = RSL_conv_1(x7)\n",
    "        x9 = RSL_conv_2(x8)\n",
    "        x10 = x7 + x9\n",
    "        \n",
    "        x11 = RSL_conv_1(x10)\n",
    "        x12 = RSL_conv_2(x11)\n",
    "        x13 = x10 + x12\n",
    "        \n",
    "        out = x13 + x1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-847478bcd37b>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-847478bcd37b>\"\u001b[1;36m, line \u001b[1;32m21\u001b[0m\n\u001b[1;33m    nn.MaxPool2d(stride = 9, padding=(4,4))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class YOLO_v4_Neck(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YOLO_v4_Module, self).__init__()\n",
    "        #self.input_size = input_size\n",
    "        #self.output_size = output_size\n",
    "        \n",
    "        self.conv_layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 512, kernel_size=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv_layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(512,1024, kernel_size=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv_layer_3 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 512, kernel_size=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.maxpool_1 = nn.Sequential(\n",
    "            nn.MaxPool2d(stride = 5, padding=(2,2))\n",
    "            nn.MaxPool2d(stride = 9, padding=(4,4))\n",
    "            nn.MaxPool2d(stride = 13, padding=(6,6))\n",
    "        )\n",
    "        \n",
    "        self.conv_layer_4 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv_layer_5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=(1,1)),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv_layer_6 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 512, kernel_size=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv_layer_7 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_layer_2 = nn.Conv2d(192, 128, kernel_size=1)\n",
    "        \n",
    "        self.conv_layer_3 = nn.Conv2d(192, 128, kernel_size=1)\n",
    "        self.conv_layer_4 = nn.Conv2d(128, 256, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_5 = nn.Conv2d(256, 256, kernel_size=1)\n",
    "        self.layer_6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "\n",
    "        \n",
    "        self.fc1 = nn.Linear(7 * 7 * 1024, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 7 * 7 * 30)\n",
    "    def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.conv_layer_3(out)\n",
    "        out = self.conv_layer_4(out)\n",
    "        out = self.conv_layer_5(out)\n",
    "        out = self.layer_6(out)\n",
    "        out = self.conv_layer_7(out)\n",
    "        out = self.conv_layer_8(out)\n",
    "        out = self.conv_layer_9(out)\n",
    "        out = self.conv_layer_10(out)\n",
    "        out = self.conv_layer_11(out)\n",
    "        out = self.conv_layer_12(out)\n",
    "        out = self.conv_layer_13(out)\n",
    "        out = self.conv_layer_14(out)\n",
    "        out = self.conv_layer_15(out)\n",
    "        out = self.layer_16(out)\n",
    "        out = self.conv_layer_17(out)\n",
    "        out = self.conv_layer_18(out)\n",
    "        out = self.conv_layer_19(out)\n",
    "        out = self.conv_layer_20(out)\n",
    "        out = self.conv_layer_21(out)\n",
    "        out = self.conv_layer_22(out)\n",
    "        out = self.conv_layer_23(out)\n",
    "        out = self.conv_layer_24(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_v4_Module(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YOLO_v4_Module, self).__init__()\n",
    "        #self.input_size = input_size\n",
    "        #self.output_size = output_size\n",
    "\n",
    "        \n",
    "        self.downsample_layer_1 = nn.Sequential(\n",
    "            nn.Identity()\n",
    "            nn.Conv2d(64, 32, kernel_size=1),\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.conv_layer_2 = nn.Conv2d(192, 128, kernel_size=1)\n",
    "        \n",
    "        self.conv_layer_3 = nn.Conv2d(192, 128, kernel_size=1)\n",
    "        self.conv_layer_4 = nn.Conv2d(128, 256, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_5 = nn.Conv2d(256, 256, kernel_size=1)\n",
    "        self.layer_6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.conv_layer_7 = nn.Conv2d(512, 256, kernel_size=1)\n",
    "        self.conv_layer_8 = nn.Conv2d(256, 512, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_9 = nn.Conv2d(512, 256, kernel_size=1)\n",
    "        self.conv_layer_10 = nn.Conv2d(256, 512, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_11 = nn.Conv2d(512, 256, kernel_size=1)\n",
    "        self.conv_layer_12 = nn.Conv2d(256, 512, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_13 = nn.Conv2d(512, 256, kernel_size=1)\n",
    "        self.conv_layer_14 = nn.Conv2d(256, 512, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_15 = nn.Conv2d(512, 512, kernel_size=1)\n",
    "        self.layer_16 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=(1,1)),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.conv_layer_17 = nn.Conv2d(1024, 512, kernel_size=1)\n",
    "        self.conv_layer_18 = nn.Conv2d(512, 1024, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_19 = nn.Conv2d(1024, 512, kernel_size=1)\n",
    "        self.conv_layer_20 = nn.Conv2d(512, 1024, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_21 = nn.Conv2d(1024, 1024, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_22 = nn.Conv2d(1024, 1024, kernel_size=3, stride=2, padding=(1,1))\n",
    "        self.conv_layer_23 = nn.Conv2d(1024, 1024, kernel_size=3, padding=(1,1))\n",
    "        self.conv_layer_24 = nn.Conv2d(1024, 1024, kernel_size=3, padding=(1,1))\n",
    "        \n",
    "        self.fc1 = nn.Linear(7 * 7 * 1024, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 7 * 7 * 30)\n",
    "    def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.conv_layer_3(out)\n",
    "        out = self.conv_layer_4(out)\n",
    "        out = self.conv_layer_5(out)\n",
    "        out = self.layer_6(out)\n",
    "        out = self.conv_layer_7(out)\n",
    "        out = self.conv_layer_8(out)\n",
    "        out = self.conv_layer_9(out)\n",
    "        out = self.conv_layer_10(out)\n",
    "        out = self.conv_layer_11(out)\n",
    "        out = self.conv_layer_12(out)\n",
    "        out = self.conv_layer_13(out)\n",
    "        out = self.conv_layer_14(out)\n",
    "        out = self.conv_layer_15(out)\n",
    "        out = self.layer_16(out)\n",
    "        out = self.conv_layer_17(out)\n",
    "        out = self.conv_layer_18(out)\n",
    "        out = self.conv_layer_19(out)\n",
    "        out = self.conv_layer_20(out)\n",
    "        out = self.conv_layer_21(out)\n",
    "        out = self.conv_layer_22(out)\n",
    "        out = self.conv_layer_23(out)\n",
    "        out = self.conv_layer_24(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
